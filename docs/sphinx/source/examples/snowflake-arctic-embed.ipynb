{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import HNSW, ApplicationPackage, Component, Field, Parameter\n",
    "\n",
    "app_name = \"snowflake\"\n",
    "\n",
    "app_package = ApplicationPackage(\n",
    "    name=app_name,\n",
    "    components=[\n",
    "        Component(\n",
    "            id=\"snow\",\n",
    "            type=\"hugging-face-embedder\",\n",
    "            parameters=[\n",
    "                Parameter(\n",
    "                    \"transformer-model\",\n",
    "                    {\n",
    "                        \"url\": \"https://huggingface.co/Snowflake/snowflake-arctic-embed-l/resolve/main/onnx/model_int8.onnx\"\n",
    "                    },\n",
    "                ),\n",
    "                Parameter(\n",
    "                    \"tokenizer-model\",\n",
    "                    {\n",
    "                        \"url\": \"https://huggingface.co/Snowflake/snowflake-arctic-embed-l/raw/main/tokenizer.json\"\n",
    "                    },\n",
    "                ),\n",
    "                Parameter(\n",
    "                    \"normalize\",\n",
    "                    {},  # Define as a simple string, not a dictionary\n",
    "                    \"true\",  # Define as a simple string, not a dictionary\n",
    "                ),\n",
    "                Parameter(\n",
    "                    \"pooling-strategy\",\n",
    "                    {},\n",
    "                    \"cls\",  # Define as a simple string, not a dictionary\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_package.schema.add_fields(\n",
    "    Field(name=\"id\", type=\"int\", indexing=[\"attribute\", \"summary\"]),\n",
    "    Field(\n",
    "        name=\"doc\", type=\"string\", indexing=[\"index\", \"summary\"], index=\"enable-bm25\"\n",
    "    ),\n",
    "    Field(\n",
    "        name=\"doc_embeddings\",\n",
    "        type=\"tensor<float>(x[384])\",\n",
    "        indexing=[\"input doc\", \"embed\", \"index\", \"attribute\"],\n",
    "        ann=HNSW(distance_metric=\"prenormalized-angular\"),\n",
    "        is_document_field=False,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import (\n",
    "    DocumentSummary,\n",
    "    FieldSet,\n",
    "    FirstPhaseRanking,\n",
    "    RankProfile,\n",
    "    SecondPhaseRanking,\n",
    "    Summary,\n",
    ")\n",
    "\n",
    "app_package.schema.add_rank_profile(\n",
    "    RankProfile(\n",
    "        name=\"semantic\",\n",
    "        inputs=[(\"query(q)\", \"tensor<float>(x[384])\")],\n",
    "        inherits=\"default\",\n",
    "        first_phase=\"closeness(field, doc_embeddings)\",\n",
    "        match_features=[\"closeness(field, doc_embeddings)\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "app_package.schema.add_rank_profile(RankProfile(name=\"bm25\", first_phase=\"bm25(doc)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_package.schema.add_rank_profile(\n",
    "    RankProfile(\n",
    "        name=\"hybrid\",\n",
    "        inherits=\"semantic\",\n",
    "        functions=[],\n",
    "        first_phase=FirstPhaseRanking(expression=\"closeness(field, doc_embeddings)\"),\n",
    "        # Notice that we use log10 here, as the bm25 values with the natural logarithm tends to dominate the closeness values for these documents.\n",
    "        second_phase=SecondPhaseRanking(expression=\"firstPhase + log10( bm25(doc))\"),\n",
    "        match_features=[\n",
    "            \"firstPhase\",\n",
    "            \"bm25(doc)\",\n",
    "        ],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_package.schema.add_field_set(FieldSet(name=\"default\", fields=[\"doc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_package.schema.add_document_summary(\n",
    "    DocumentSummary(\n",
    "        name=\"minimal\",\n",
    "        summary_fields=[Summary(\"id\", \"int\"), Summary(\"doc\", \"string\")],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some sample documents that will help us see where the different ranking strategies have their strengths and weaknesses.\n",
    "\n",
    "> These documents were created by ChatGPT.\n",
    "\n",
    "Looking through the documents, we can see that a ranking of the documents in the order they are presented seem quite reasonable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query that the user is searching for\n",
    "query = \"How does Vespa handle real-time indexing and search?\"\n",
    "\n",
    "# List of documents simulating content in the search engine\n",
    "documents = [\n",
    "    \"Vespa excels in real-time data indexing and its ability to search large datasets quickly.\",\n",
    "    \"Instant data availability and maintaining query performance while simultaneously indexing are key features of the Vespa search engine.\",\n",
    "    \"With our search solution, real-time updates are seamlessly integrated into the search index, enhancing responsiveness.\",\n",
    "    \"While not as robust as Vespa, our vector database strives to meet your search needs, despite certain, shall we say, 'flexible' features.\",\n",
    "    \"Search engines like ours utilize complex algorithms to handle immediate data querying and indexing.\",\n",
    "    \"Modern search platforms emphasize quick data retrieval from continuously updated indexes.\",\n",
    "    \"Discover the history and cultural impact of the classic Italian Vespa scooter brand.\",\n",
    "    \"Tips for maintaining your Vespa to ensure optimal performance and longevity of your scooter.\",\n",
    "    \"Review of different scooter brands including Vespa, highlighting how they handle features like speed, cost, and aesthetics, and how consumers search for the best options.\",\n",
    "    \"Vespa scooter safety regulations and best practices for urban commuting.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumping the application package to files\n",
    "\n",
    "This is a good practice to inspect and understand the structure of the application package and schema files, generated by pyvespa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_package.to_files(\"snowflake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for configuration server, 0/60 seconds...\n",
      "Waiting for configuration server, 5/60 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 0/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 5/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Waiting for application status, 10/300 seconds...\n",
      "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
      "Application is up!\n",
      "Finished deployment.\n"
     ]
    }
   ],
   "source": [
    "from vespa.deployment import VespaDocker\n",
    "\n",
    "vespa_docker = VespaDocker()\n",
    "app = vespa_docker.deploy(app_package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_docs = [\n",
    "    {\n",
    "        \"id\": str(i),\n",
    "        \"fields\": {\n",
    "            \"doc\": doc,\n",
    "        },\n",
    "    }\n",
    "    for i, doc in enumerate(documents)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.io import VespaResponse\n",
    "\n",
    "\n",
    "def callback(response: VespaResponse, id: str):\n",
    "    if not response.is_successful():\n",
    "        print(\n",
    "            f\"Failed to feed document {id} with status code {response.status_code}: Reason {response.get_json()}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.feed_iterable(feed_docs, schema=app_package.schema.name, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use the [Vespa CLI](https://docs.vespa.ai/en/vespa-cli) `visit` command to retrieve all indexed documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"id:snowflake:snowflake::2\",\"fields\":{\"doc\":\"With our search solution, real-time updates are seamlessly integrated into the search index, enhancing responsiveness.\"}}\n",
      "{\"id\":\"id:snowflake:snowflake::4\",\"fields\":{\"doc\":\"Search engines like ours utilize complex algorithms to handle immediate data querying and indexing.\"}}\n",
      "{\"id\":\"id:snowflake:snowflake::1\",\"fields\":{\"doc\":\"Instant data availability and maintaining query performance while simultaneously indexing are key features of the Vespa search engine.\"}}\n",
      "{\"id\":\"id:snowflake:snowflake::5\",\"fields\":{\"doc\":\"Modern search platforms emphasize quick data retrieval from continuously updated indexes.\"}}\n",
      "{\"id\":\"id:snowflake:snowflake::3\",\"fields\":{\"doc\":\"While not as robust as Vespa, our vector database strives to meet your search needs, despite certain, shall we say, 'flexible' features.\"}}\n",
      "{\"id\":\"id:snowflake:snowflake::6\",\"fields\":{\"doc\":\"Discover the history and cultural impact of the classic Italian Vespa scooter brand.\"}}\n",
      "{\"id\":\"id:snowflake:snowflake::8\",\"fields\":{\"doc\":\"Review of different scooter brands including Vespa, highlighting how they handle features like speed, cost, and aesthetics, and how consumers search for the best options.\"}}\n",
      "{\"id\":\"id:snowflake:snowflake::9\",\"fields\":{\"doc\":\"Vespa scooter safety regulations and best practices for urban commuting.\"}}\n",
      "{\"id\":\"id:snowflake:snowflake::7\",\"fields\":{\"doc\":\"Tips for maintaining your Vespa to ensure optimal performance and longevity of your scooter.\"}}\n",
      "{\"id\":\"id:snowflake:snowflake::0\",\"fields\":{\"doc\":\"Vespa excels in real-time data indexing and its ability to search large datasets quickly.\"}}\n"
     ]
    }
   ],
   "source": [
    "!vespa visit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute a metric\n",
    "\n",
    "If we assume that the documents are created in decreasing order of relevance, we can compute the Normalized Discounted Cumulative Gain (NDCG) metric for the different ranking strategies.\n",
    "\n",
    "The NDCG is a measure of ranking quality. It is calculated as the sum of the discounted gain of the relevant documents, divided by the ideal DCG. The ideal DCG is the DCG of the perfect ranking, where the documents are ordered by relevance.\n",
    "\n",
    "The formula for NDCG is:\n",
    "\n",
    "$$\n",
    "NDCG = \\frac{DCG}{IDCG}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "DCG = \\sum_{i=1}^{n} \\frac{2^{rel_i} - 1}{\\log_2(i + 1)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG@3: 0.6618\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def ndcg_at_k(rank_order: List[int], ideal_order: List[int], k: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the normalized Discounted Cumulative Gain (nDCG) at position k.\n",
    "\n",
    "    Parameters:\n",
    "        rank_order (List[int]): The list of document indices as ranked by the search system.\n",
    "        ideal_order (List[int]): The list of document indices in the ideal order.\n",
    "        k (int): The position up to which to calculate nDCG.\n",
    "\n",
    "    Returns:\n",
    "        float: The nDCG value at position k.\n",
    "    \"\"\"\n",
    "    dcg = 0.0\n",
    "    idcg = 0.0\n",
    "\n",
    "    # Calculate DCG based on the ranked order up to k\n",
    "    for i in range(min(k, len(rank_order))):\n",
    "        rank_index = rank_order[i]\n",
    "        # Find the rank index in the ideal order to assign relevance\n",
    "        if rank_index in ideal_order:\n",
    "            relevance = len(ideal_order) - ideal_order.index(rank_index)\n",
    "        else:\n",
    "            relevance = 0\n",
    "        dcg += relevance / math.log2(i + 2)\n",
    "\n",
    "    # Calculate IDCG based on the ideal order up to k\n",
    "    for i in range(min(k, len(ideal_order))):\n",
    "        relevance = len(ideal_order) - i\n",
    "        idcg += relevance / math.log2(i + 2)\n",
    "\n",
    "    # Handle the case where IDCG is zero to avoid division by zero\n",
    "    if idcg == 0:\n",
    "        return 0.0\n",
    "    return dcg / idcg\n",
    "\n",
    "\n",
    "# Example usage\n",
    "rank_order = [5, 6, 1]  # Example ranked order indices\n",
    "ideal_result_order = [0, 1, 2, 4, 5, 3, 6, 7, 8, 9]  # Example ideal order indices\n",
    "\n",
    "# Calculate nDCG@3\n",
    "result = ndcg_at_k(rank_order, ideal_result_order, 3)\n",
    "print(f\"nDCG@3: {result:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the different rank profiles to evaluate\n",
    "\n",
    "rank_profiles = {\n",
    "    \"unranked\": {\n",
    "        \"yql\": f\"select * from {app_name} where true\",\n",
    "        \"ranking.profile\": \"unranked\",\n",
    "    },\n",
    "    \"bm25\": {\n",
    "        \"yql\": f\"select * from {app_name} where userQuery()\",\n",
    "        \"ranking.profile\": \"bm25\",\n",
    "    },\n",
    "    \"semantic\": {\n",
    "        \"yql\": f\"select * from {app_name} where {{targetHits:5}}nearestNeighbor(doc_embeddings,q)\",\n",
    "        \"ranking.profile\": \"semantic\",\n",
    "        \"input.query(q)\": f\"embed({query})\",\n",
    "    },\n",
    "    \"hybrid\": {\n",
    "        \"yql\": f\"select * from {app_name} where userQuery() or ({{targetHits:5}}nearestNeighbor(doc_embeddings,q))\",\n",
    "        \"ranking.profile\": \"hybrid\",\n",
    "        \"input.query(q)\": f\"embed({query})\",\n",
    "    },\n",
    "    \"hybrid_filtered\": {\n",
    "        \"yql\": f'select * from {app_name} where !(doc contains \"scooter\") and userQuery() or ({{targetHits:5}}nearestNeighbor(doc_embeddings,q))',\n",
    "        \"ranking.profile\": \"hybrid\",\n",
    "        \"input.query(q)\": f\"embed({query})\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Define some common params that will be used for all queries\n",
    "\n",
    "common_params = {\n",
    "    \"query\": query,\n",
    "    \"hits\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Tuple\n",
    "\n",
    "from vespa.application import Vespa\n",
    "from vespa.io import VespaQueryResponse\n",
    "\n",
    "\n",
    "def evaluate_rank_profile(\n",
    "    app: Vespa, rank_profile: str, params: dict, k: int\n",
    ") -> Tuple[float, List[str]]:\n",
    "    \"\"\"\n",
    "    Run a query against a Vespa application using a specific rank profile and parameters.\n",
    "    Evaluate the nDCG@3 of the search results based on the ideal order.\n",
    "\n",
    "    Parameters:\n",
    "        app (Vespa): The Vespa application to query.\n",
    "        rank_profile (str): The name of the rank profile to use.\n",
    "        params (dict): The common parameters to use in addition to the rank profile specific parameters.\n",
    "        k (int): The position up to which to calculate nDCG.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: The search results\n",
    "    \"\"\"\n",
    "    body_params = {\n",
    "        **rank_profiles[rank_profile],\n",
    "        **params,\n",
    "    }\n",
    "    response: VespaQueryResponse = app.query(body_params)\n",
    "    rankings = [int(hit[\"id\"][-1]) for hit in response.hits]\n",
    "    docs = [hit[\"fields\"][\"doc\"] for hit in response.hits]\n",
    "    ndcg = ndcg_at_k(rankings, ideal_order=ideal_result_order, k=3)\n",
    "    return ndcg, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank profile: unranked, nDCG@3: 0.66\n",
      "[\n",
      "  \"Modern search platforms emphasize quick data retrieval from continuously updated indexes.\",\n",
      "  \"Discover the history and cultural impact of the classic Italian Vespa scooter brand.\",\n",
      "  \"Instant data availability and maintaining query performance while simultaneously indexing are key features of the Vespa search engine.\"\n",
      "]\n",
      "Rank profile: bm25, nDCG@3: 0.78\n",
      "[\n",
      "  \"Vespa excels in real-time data indexing and its ability to search large datasets quickly.\",\n",
      "  \"Review of different scooter brands including Vespa, highlighting how they handle features like speed, cost, and aesthetics, and how consumers search for the best options.\",\n",
      "  \"With our search solution, real-time updates are seamlessly integrated into the search index, enhancing responsiveness.\"\n",
      "]\n",
      "Rank profile: semantic, nDCG@3: 1.00\n",
      "[\n",
      "  \"Vespa excels in real-time data indexing and its ability to search large datasets quickly.\",\n",
      "  \"Instant data availability and maintaining query performance while simultaneously indexing are key features of the Vespa search engine.\",\n",
      "  \"With our search solution, real-time updates are seamlessly integrated into the search index, enhancing responsiveness.\"\n",
      "]\n",
      "Rank profile: hybrid, nDCG@3: 0.82\n",
      "[\n",
      "  \"Vespa excels in real-time data indexing and its ability to search large datasets quickly.\",\n",
      "  \"With our search solution, real-time updates are seamlessly integrated into the search index, enhancing responsiveness.\",\n",
      "  \"Review of different scooter brands including Vespa, highlighting how they handle features like speed, cost, and aesthetics, and how consumers search for the best options.\"\n",
      "]\n",
      "Rank profile: hybrid_filtered, nDCG@3: 0.94\n",
      "[\n",
      "  \"Vespa excels in real-time data indexing and its ability to search large datasets quickly.\",\n",
      "  \"With our search solution, real-time updates are seamlessly integrated into the search index, enhancing responsiveness.\",\n",
      "  \"Search engines like ours utilize complex algorithms to handle immediate data querying and indexing.\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "for rank_profile, params in rank_profiles.items():\n",
    "    ndcg, docs = evaluate_rank_profile(\n",
    "        app, rank_profile=rank_profile, params=common_params, k=3\n",
    "    )\n",
    "    print(f\"Rank profile: {rank_profile}, nDCG@3: {ndcg:.2f}\")\n",
    "    print(json.dumps(docs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In short, the above query demonstrates how easy it is to combine various ranking strategies,\n",
    "and also combine with filters.\n",
    "\n",
    "To learn more about pre-filtering vs post-filtering,\n",
    "read [Filtering strategies and serving performance](https://blog.vespa.ai/constrained-approximate-nearest-neighbor-search/).\n",
    "[Semantic search with multi-vector indexing](https://blog.vespa.ai/semantic-search-with-multi-vector-indexing/)\n",
    "is a great read overall for this domain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Check out global reranking strategies, and try to introduce a global_phase reranking strategy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vespa_docker.container.stop()\n",
    "# vespa_docker.container.remove()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvespa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
