{"cells":[{"cell_type":"markdown","id":"d551cc4e","metadata":{"id":"b3ae8a2b"},"source":[]},{"cell_type":"markdown","id":"0dd50339","metadata":{},"source":["<picture>\n","  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://vespa.ai/assets/vespa-ai-logo-heather.svg\">\n","  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://vespa.ai/assets/vespa-ai-logo-rock.svg\">\n","  <img alt=\"#Vespa\" width=\"200\" src=\"https://vespa.ai/assets/vespa-ai-logo-rock.svg\" style=\"margin-bottom: 25px;\">\n","</picture>\n","\n","# Billion-scale vector search with Cohere binary embeddings in Vespa\n","\n","Cohere just released a new embedding API with support for binary and `int8` vectors. Read the announcement \n","in the blog post: [Cohere int8 & binary Embeddings - Scale Your Vector Database to Large Datasets](https://txt.cohere.com/int8-binary-embeddings/).\n","\n","> We are excited to announce that Cohere Embed is the first embedding model that natively supports int8 and binary embeddings.\n","\n","This is huge because:\n","\n","- Binarization reduces the storage (disk/memory) footprint from 1024 floats (4096 bytes) per vector to 128 bytes.\n","- Faster distance calculations using [hamming](https://docs.vespa.ai/en/reference/schema-reference.html#distance-metric) distance that\n","Vespa natively supports for bits packed into `int8` tensor cells. More on [hamming distance in Vespa](https://docs.vespa.ai/en/reference/schema-reference.html#hamming).\n","- Multiple vector representations allow for coarse retrieval in hamming space and subsequent phases using higher-resolution representations. \n","- Drastically reduces the deployment due to tiered storage economics. \n","\n","Vespa supports `hamming` distance with and without [HNSW indexing](https://docs.vespa.ai/en/approximate-nn-hnsw.html). \n","\n","For those wanting to learn more about binary vectors, we recommend our 2021 blog series on [Billion-scale vector search with Vespa](https://blog.vespa.ai/billion-scale-knn/) \n","and [Billion-scale vector search with Vespa - part two](https://blog.vespa.ai/billion-scale-knn-part-two/).\n","\n","This notebook demonstrates using the Cohere embeddings with a coarse-to-fine search and re-ranking pipeline that reduces costs, but\n","offers the same retrieval (nDCG) accuracy. \n","\n","\n","- The packed binary vector representation is stored in memory, with an optional HNSW index using hamming distance. \n","- The `int8` vector representation is stored on disk using Vespa's [paged](https://docs.vespa.ai/en/attributes.html#paged-attributes) option.\n","\n","At query time:\n","- Retrieve in hamming space (1000 candidates) as the coarse-level search using the compact binary representation.\n","- Re-rank by using a dot product between the float version of the query vector (1024 dims) against an unpacked float version of the binary embedding (also 1024 dims)\n","- A re-ranking phase using the 1024 dimensional int8 representations. This stage pages the vector data from the disk using Vespa's [paged](https://docs.vespa.ai/en/attributes.html#paged-attributes) option (unless it is already cached).\n","\n","\n","Install the dependencies:"]},{"cell_type":"code","execution_count":null,"id":"daf34cf5","metadata":{"id":"4ffa3cbe"},"outputs":[],"source":["!pip3 install -U pyvespa cohere"]},{"cell_type":"markdown","id":"b3f11700","metadata":{},"source":["## Examining the Cohere embeddings\n","\n","Let us check out the Cohere embedding API and how we can obtain vector embeddings with different precisions for the same text input (without paying any\n","additional cost). "]},{"cell_type":"code","execution_count":3,"id":"e2371493","metadata":{},"outputs":[],"source":["import cohere\n","#Make sure that the environment variable CO_API_KEY is set to your API key\n","co = cohere.Client()"]},{"cell_type":"markdown","id":"3b68ebc1","metadata":{},"source":["### Some sample documents\n","\n","Define a few sample documents that we want to embed"]},{"cell_type":"code","execution_count":4,"id":"c9b35db3","metadata":{},"outputs":[],"source":["documents = [\n","    \"Alan Turing  was an English mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist.\",\n","    \"Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time.\",\n","    \"Isaac Newton was an English polymath active as a mathematician, physicist, astronomer, alchemist, theologian, and author who was described in his time as a natural philosopher.\",\n","    \"Marie Curie was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity\"\n","]"]},{"cell_type":"code","execution_count":5,"id":"d4edb2c7","metadata":{},"outputs":[],"source":["\n","# Compute the  embeddings of our sample documents. \n","#Set input_type to \"search_document\" and embedding_types to \"binary\" and \"int8\"\n","embeddings = co.embed(\n","  documents,\n","  model=\"embed-english-v3.0\", \n","  input_type=\"search_document\", \n","  embedding_types=[\"binary\", \"int8\"])"]},{"cell_type":"code","execution_count":6,"id":"837c5ab4","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["cohere.Embeddings {\n","\tresponse_type: embeddings_by_type\n","\tembeddings: cohere.EmbeddingsByType {\n","\tfloat: None\n","\tint8: [[-22, -22, -52, 18, -42, -48, 2, -8, 5, 44, 73, 9, 3, -44, -25, 15, 19, 4, 18, -18, 6, 17, 0, -61, -14, 46, -8, -13, 20, 22, 10, -41, 10, 48, -20, 41, -8, 8, 29, 0, -27, 12, -39, -27, -93, 33, -89, 4, 14, -41, -12, -3, 7, -22, -15, -21, 47, -9, 88, -107, -91, -50, 65, 26, 5, 5, 52, 27, -15, -4, 13, -6, 6, -1, -16, 13, 17, 73, 26, -9, -4, -1, 56, -16, -6, 6, -16, -25, -23, -38, -38, 78, -62, -27, -53, -20, -3, -8, -9, -18, 9, -25, 14, -12, -40, 90, 39, 24, -48, -6, -11, -117, 36, -56, -15, -1, -6, 30, 31, 7, 44, 80, 36, -36, -24, -13, -36, -64, 44, -12, -36, 46, -43, -68, -39, 12, 34, -8, 0, 58, -8, -4, 49, 4, 9, 45, 44, -34, -52, -26, -53, 27, -68, 22, 33, 29, -32, 37, 38, 84, -18, 19, 65, -18, 5, -56, -56, 20, 19, -20, -3, 19, 43, -15, -8, 29, -45, -39, -43, 121, 73, -49, -128, 127, -19, 41, -10, 55, 39, 13, -66, 1, -52, -34, 58, 6, -59, -35, 20, -10, -21, 58, -50, 27, -1, -27, 0, 33, 36, 39, -22, -7, 0, -43, -34, -4, -2, -27, -37, -19, -48, 30, -60, 33, -79, 28, -51, 38, -46, 7, 99, 0, 46, 22, -39, -14, -1, -87, 22, 65, 41, -47, -66, -109, 73, 77, 47, -79, -17, 28, 8, -3, -2, -35, -13, 34, -41, 25, -2, 13, -17, 57, 98, -31, -25, -23, -2, -7, -13, -32, 22, -13, 7, 63, -65, -12, 5, -11, 0, 27, 5, 50, 35, -7, 11, 64, 9, 30, 31, -15, 2, 53, 23, 53, 22, -19, -30, 89, -19, -17, -69, -5, -7, -79, 6, -2, 23, 8, 18, -10, -14, 8, 21, 16, -13, -58, -37, -8, -86, -33, -22, 7, -40, -13, 5, 27, -78, -2, -5, -39, 42, 1, 4, 22, 15, -7, -2, 49, -26, -68, -48, -37, -7, -26, -27, 45, 9, 4, -34, 47, -59, -19, 10, 44, 56, -123, -38, 110, -25, -10, 18, 29, 8, -41, -25, -51, 9, 20, 68, 46, -45, 44, -68, 0, 41, 35, 39, -28, 14, 22, 25, 71, -28, 32, -18, 59, 15, 7, 10, -40, 21, 72, 51, -26, -19, -26, -36, 40, -34, 23, 127, -24, -26, 77, -89, 104, 45, 37, 30, -37, 23, -34, -2, -50, 0, -35, -44, -8, 41, 1, -51, 71, -60, 4, -18, -26, 20, 20, 2, 30, 6, -19, -12, 3, 23, 88, -13, -12, -31, -36, 51, 15, -3, 14, 5, -42, 17, 29, 13, 23, -17, 8, 23, 25, -35, -60, 21, 56, 4, 2, 29, -36, -40, 33, 12, -35, 46, 9, -28, 31, 18, 11, 5, 3, 7, 18, -30, 25, -55, 7, 7, 0, 64, -35, -33, 19, -72, -35, -21, -78, -81, 2, -1, -54, -17, -6, -24, 98, 47, -46, 47, -12, -34, -21, 44, 7, -16, 44, -5, 27, -7, -9, 20, 43, -44, 16, -21, 36, -36, -18, -40, -21, 17, 4, 13, 12, 12, 57, 0, -11, 121, 15, 58, 29, -86, 12, -42, 18, 47, -17, -27, -28, -26, 56, -19, 20, -6, 34, -1, -9, 3, 8, 27, -17, -35, -4, -20, 11, 4, 36, 4, -7, 26, -40, 127, 23, -30, -111, 38, -15, -35, -22, 5, -16, -23, -36, -23, 45, -38, 15, 47, 5, -49, 51, -28, -20, -7, -51, -51, -53, 33, 4, 17, -63, -2, 12, -36, -38, -19, -9, -42, 46, -14, -22, 72, 93, 105, -27, -6, 13, -24, -47, 3, 25, -6, -30, 22, -46, -96, -34, 22, -44, 44, 40, -2, -9, -45, 14, -11, 23, 18, 0, -44, 11, 25, -29, -29, -6, -19, -20, 47, 35, 38, -24, -19, 25, 19, -10, -14, 3, -50, -3, -9, -22, 17, -2, -65, 36, 15, 30, 14, 106, -46, 28, 11, 18, -22, 53, -41, 58, 9, -14, -28, -9, -11, 12, -19, 21, -38, 4, 0, -18, -14, 27, -51, 21, -22, 23, 52, 5, -3, 26, 4, 27, 27, 60, 1, -13, -21, -14, 10, 7, 13, 21, 1, -5, -38, 7, 3, -2, 4, 42, -46, -12, 38, 0, -10, -7, -38, 6, -38, 23, 17, -38, 26, 14, -60, -23, 27, 36, 6, 54, -22, -19, 30, -79, 17, 19, -24, 17, 111, -54, 61, -55, 7, 85, 17, 61, 11, 26, -6, 58, 15, 21, 25, -16, 14, 15, 7, -13, -83, -2, -17, 39, 21, 60, 33, 40, -69, 36, 14, 19, -3, -2, -38, 14, -5, -40, -8, 3, 49, 16, 54, -6, 3, -12, -5, 5, -6, 25, -65, 47, -25, -28, -41, 31, 57, -35, 30, -7, -4, -27, -36, -23, -34, 39, -2, -25, 2, 59, 10, 16, -14, -55, -7, -6, -110, -14, -47, -84, 77, 71, -10, 6, 13, -72, -32, 69, 7, -27, 9, -42, -40, -28, 29, -12, 26, -58, 74, -1, -50, 38, -81, -40, 42, -49, -23, 25, 0, 86, -8, -4, -1, -18, 1, 58, 11, -34, -42, -24, -33, 24, 2, 23, 3, -43, -33, -19, 14, -70, 7, 26, -14, -91, -57, -30, -10, -46, -34, 7, 14, 79, 109, 27, 32, 4, -9, 27, 67, 2, 40, -17, -19, 62, 23, 48, -20, 6, -88, 74, -60, -53, 66, -77, -31, 1, -3, -43, 22, -44, -33, 20, 59, 58, -65, -49, 116, 76, 127, 24, -29, 59, 10, -20, -57, -19, -3, 36, 19, 2, 34, 6, 55, 27, 35, -3, -54, 32, 21, -4, -12, -34, -50, -15, 1, -22, 75, -48, -52, -26, -12, 2, -9, -17, -25, -3, -60, -128, -3, -18, -23, -17, -4, -5, -5, 36, -9, -21, -1, -16, 49, 6, -31, -21, -18, -12, 33, -11, -28, 16, -31, 41, -19, 0, 57, -4, -10, 16, 27, -27, 5, 103, -53, 39, -6, -8, 3, 0, 4, 38, -47, 33, 10, 26, -19, 53, 42, 31, 15, 12, 1, 44, -67, -18, -87, -29, 27, 3, 56, -7, -5, 37, -1, 13], [-19, -42, -31, 10, -43, -28, 0, -20, -10, 81, 107, 15, 35, -44, -28, 52, -4, 31, 17, -24, 17, -17, -40, -66, 31, -74, -39, 17, -3, 2, 13, 37, -7, 49, -7, 41, 8, 11, 41, 23, 12, 0, -30, -20, -39, 10, -21, -28, 27, -32, -11, 25, 11, -44, -24, -37, 110, -75, 73, -125, -88, -58, 103, 43, 20, -14, -25, 9, -3, 55, 22, -23, -3, 9, -25, 0, 26, 37, 30, 0, -26, 12, 40, -7, -43, -17, -39, -13, 10, 8, -11, 41, -31, 64, 1, -43, 2, 14, -35, -31, 17, -46, 21, -19, -40, 124, 32, 54, -63, -7, 13, -128, 28, 9, -29, -17, -18, 50, 5, 47, 25, 70, 61, -86, -9, -8, -28, -91, 89, 7, -20, 19, -41, -27, -17, 4, -10, 40, -7, 67, -45, -51, 46, -1, 5, 38, 35, -16, 1, -56, -16, 17, -26, 7, 20, -11, -28, 7, 52, 30, -37, -5, 20, 20, 0, 0, 45, 15, 33, 31, 29, -5, 55, 6, -21, -4, -3, -123, -23, 127, 71, 5, -128, 83, 31, -52, -14, -50, 29, 23, -21, 3, -45, -21, 16, 38, -65, 29, -3, -31, 18, 11, 26, 3, 5, 18, -11, 31, 92, 24, -39, -3, 2, -32, -67, 14, -7, 8, -39, 49, -44, 6, -52, -1, -24, 45, -50, 29, 19, 21, 99, -20, -26, 54, -2, 15, 69, 29, 14, -24, -4, -92, -42, 38, -30, 47, 17, 11, 37, 24, -18, -65, 13, -111, 39, 13, 16, 70, -77, 30, -39, 55, 43, -3, -22, 13, -36, -21, -62, 50, 56, -64, 8, 60, -81, 22, -12, 7, -3, 38, -17, 54, 11, -16, -18, -20, 23, -5, -14, -48, 31, -15, -21, 15, -25, -34, -39, 2, 27, -15, -53, 63, -2, 6, -9, 2, -19, 4, 0, -33, -20, 27, 17, -9, -12, -42, -9, -1, -66, -33, -6, -20, 18, 0, -10, 1, -6, 10, -6, 5, 127, 70, 37, 0, 50, -14, 28, -31, -12, 20, 30, 30, 0, -71, -50, 67, 9, 25, -26, 30, -43, -40, -26, -12, -1, -78, 24, 47, -33, -22, 1, -11, -22, -16, 35, -25, -23, 8, 6, 2, -29, 29, -87, -20, -6, 50, 1, -51, 24, -11, -12, 29, 24, 43, 4, 30, -44, -8, 14, 2, -11, -17, 17, -27, 54, -28, 5, 111, -99, -22, 127, 2, -1, 52, -86, 94, 23, 36, 22, -16, -13, 6, -58, 1, -26, -21, -102, 0, -17, 16, -51, 99, -73, 28, 47, 46, 10, -49, 50, 39, 45, -14, -34, -7, 15, 102, -1, 48, -21, 0, 42, -9, -8, 66, -11, 4, -34, -2, 52, 0, 15, -8, 57, 4, -33, -9, 50, 51, 21, 43, 63, 1, -53, 40, -42, -21, 98, 6, -48, 19, -39, 26, 6, 31, -10, 57, -31, 3, -41, 32, -1, 11, 34, -28, -47, 35, -75, -34, -5, -47, -51, -19, 30, -29, 14, -15, -32, 100, 42, -51, 46, -25, -78, -1, 44, 7, 20, 52, 4, 83, 45, 6, 45, 49, -16, -2, 80, 3, 22, -23, -39, -28, 20, 33, -13, 10, -22, 18, 12, 32, 78, -9, 45, 29, -50, -22, -4, 28, 22, -51, 8, 11, -26, -1, -20, 31, -34, 27, -12, -1, -9, -15, 29, -2, -29, -85, -53, -20, 19, 69, 48, -23, -6, -21, 92, 19, -63, -128, 30, -8, -52, -34, 53, 43, -24, -41, 9, 36, -33, -28, -2, 25, 3, 44, -61, 33, 32, -7, -31, -1, 20, 7, -32, -16, -3, 19, 64, 28, 63, -3, -17, 23, 3, -25, -10, 59, 45, -22, 14, 7, -12, -29, -21, 47, -18, -25, 2, -20, -27, -38, 16, -4, 5, 9, 18, -36, -42, -55, -41, -10, -66, -2, -55, -87, -5, 50, 1, -2, -20, -9, 60, 14, 11, -59, -62, -14, -15, -19, 2, 6, -19, -1, -47, 4, 50, -18, -33, 36, 0, 13, 19, 113, -10, 5, 21, -13, 1, 22, -23, 11, -31, 10, -51, -39, -4, 1, 78, 31, 28, -98, -8, -53, -12, 15, -19, 30, -15, -2, 43, 15, 53, 93, 0, 55, 24, 18, -22, -51, -3, 2, 4, -26, 13, -27, -16, 59, 26, -16, 9, 4, 10, 24, -16, -15, 43, -19, 36, 32, -18, -13, -34, -21, 3, -28, 19, -4, -38, -21, 13, 40, -38, 31, 13, -35, -2, -52, -6, 4, -60, -21, 55, -29, 11, -48, -14, 11, -4, 27, -22, -43, 5, 41, -58, 25, 10, 17, -33, 34, -60, 31, -50, 19, 34, 12, 19, 66, -56, -1, -17, 40, 26, 90, 20, 16, -128, -10, 4, -31, -42, -18, 36, 9, 66, 3, -21, -13, 17, 19, 9, 26, -37, 47, 9, 34, 34, 36, 15, -14, 55, -6, -64, -14, -84, 4, -30, 36, -5, -27, 21, 35, 15, 32, 0, 34, -12, 73, -68, -1, -49, -51, 21, 37, -44, 73, -1, -11, 14, -43, 22, -49, -28, -35, 61, 47, 84, -4, -10, -53, 41, -21, -15, 11, -59, 1, -2, -57, -13, 11, 20, 4, 38, -75, -23, 19, 21, -14, -24, -55, -69, 54, 55, -82, -60, 6, 17, -74, -39, -25, -40, -82, 0, 34, -74, -101, -50, -39, -26, 42, -67, 1, -51, -10, 24, -27, 22, -43, 7, 13, 72, 5, 60, 0, -7, 89, 56, 58, -37, 1, -83, 88, -64, -55, -12, -60, -58, 21, 25, -54, 15, -41, -57, -15, 24, 19, -41, 27, 48, 40, 79, 12, -38, 30, -8, 16, 4, 5, 4, -34, -59, 45, 55, -7, -11, 0, 10, -22, -17, 36, 4, -6, 4, -24, -34, -23, -2, 57, 50, -32, -73, -36, -56, 37, -46, 7, 2, 12, -40, 21, 13, 39, 15, 8, 0, -28, -21, -16, 3, 17, 58, 1, -25, -12, 0, -14, -11, -47, -13, -2, -36, -45, -4, -44, -47, -32, -2, 7, -18, 11, -22, 23, -11, 17, 19, 37, -4, -8, 53, -27, 43, -20, -28, -20, 17, -27, -41, 7, -17, 91, 32, 19, -6, 81, -61, -39, -85, -35, -3, -61, 5, -34, -8, -32, -32, 20], [4, 6, -45, -34, -3, -37, -11, -11, -18, 36, 27, 58, -18, -33, 25, -6, -3, 67, 44, 8, 0, 40, -35, -57, 2, -35, -7, 12, 9, 1, 19, -3, 18, 37, 3, 58, -16, 28, 50, -19, 20, -15, -59, -47, -98, 61, -61, 48, 7, -49, -4, -35, 10, -30, -38, -36, 61, -76, 48, -48, -57, -42, 70, 12, 3, -2, 84, 32, -35, -22, 23, 17, 12, -33, -5, -30, -1, -14, 39, 13, 35, 64, -4, -65, 25, -60, -14, -19, -58, -27, -48, -34, -87, 6, 11, -23, -33, -87, 3, 23, 51, -50, 73, -3, -33, 100, 4, 86, -9, 9, 18, -104, 41, -10, -64, -19, -3, -6, 10, -18, -4, 12, 77, -36, 33, 7, -56, -33, 66, -40, -25, 76, -62, -88, -58, 32, 4, 22, 23, 8, -1, -43, 39, 39, -7, -24, 7, 14, 13, 23, -42, 21, -36, 4, 26, 30, -25, 32, -1, 66, 12, 6, 15, 9, -15, -22, 10, 7, 29, -27, -4, 12, 53, 21, 16, 69, -1, -53, -50, 127, 98, -2, -128, 116, -8, -27, 11, 20, -3, 10, 17, 7, -37, -23, 66, 11, -37, -19, 31, -62, 29, 46, -34, -12, -57, -16, -14, 35, 48, 38, -16, -7, -5, -5, -18, -25, -22, -47, -25, -17, -7, 23, -27, 64, -22, 1, -30, 5, -32, 13, 17, 16, 23, 37, -1, 21, 46, -50, 19, 21, 48, -71, -17, -18, 33, 16, 32, -31, -4, 69, -55, 38, 3, -43, -22, 68, -50, 33, -32, 9, -7, 112, 84, 18, -22, -3, 1, 0, -9, -14, 26, -22, 17, 102, -48, -16, 26, -22, -31, 39, -22, 29, -6, -25, -21, -56, 11, -4, 16, -9, 40, 15, 8, 36, -13, -33, -88, 37, 23, -20, -68, 43, -16, -15, 8, 5, -29, 21, 22, -12, -55, 9, 23, -32, 21, -36, -23, -4, -54, -3, 28, -28, 19, -49, -1, -20, -60, 2, -29, 42, -10, 47, 24, 100, -11, 9, -9, 12, -41, -11, -50, -11, 16, -64, 19, 50, 33, 27, -46, 67, -75, -44, 3, 41, 62, -80, -31, 71, 13, -30, -27, 26, -22, 16, -12, -23, 8, 25, 16, 12, -63, 34, -13, -10, 8, 29, 17, -29, 16, 20, 38, 44, 22, 12, 12, 29, -23, -26, 26, -24, -7, 27, 41, -24, 10, -7, -46, 1, -63, 16, 127, -22, -8, 52, -59, 73, 55, 40, 18, 1, -13, -9, -42, -8, -11, -9, -71, 1, -2, 26, -50, 80, -63, 20, -3, 16, -24, 10, -7, -10, 0, -32, -9, -2, -12, 57, -4, 37, 0, -41, 51, 29, -20, 18, -17, -22, 46, 29, 36, 9, 21, -25, 42, 9, -31, 49, 22, 14, -3, 33, 35, 26, -73, -13, -33, -78, 95, -2, 1, -16, -49, 92, -27, 7, 12, 77, -13, -13, -41, 18, -57, 19, -29, -13, -45, 28, -45, -12, -8, 0, -16, 2, 47, -27, -8, 30, -38, 127, 40, -29, 14, -17, -16, 9, 14, -9, 41, 28, 18, 62, 16, 3, 45, 4, -23, 41, -35, 46, -31, -28, 4, -10, 19, 35, 0, -15, -15, -23, -29, 32, 43, 16, 23, -14, 7, -13, -53, 9, 69, 40, -2, -8, -26, 82, 0, -24, -29, 38, -94, 54, -32, -22, 20, -26, -13, -128, -39, -21, 48, 79, 36, 6, -5, -45, 33, 17, -37, -103, 56, -41, -41, -46, -17, -29, 7, 11, 25, 60, 10, -28, 54, -66, -62, -9, -41, 26, 31, 12, -23, -24, -18, -3, -15, -55, 20, 47, -47, -39, -3, 6, 2, 18, -6, -13, -1, 63, 112, -18, -10, -10, -6, -62, -20, 52, -25, 9, 75, -49, -42, -43, 2, 26, 5, 1, -25, -63, -21, -27, -25, -1, 1, 19, -47, -38, -17, 12, -23, -41, -3, 19, 23, 37, 42, -102, 71, 5, -13, 52, -19, -29, -66, 2, -48, 29, 54, 9, -11, -14, -38, 3, 50, 63, -109, 62, 8, 21, -29, 57, -30, -2, 21, -15, -37, 27, 10, -47, 13, 1, -93, 10, -7, 6, 45, -5, -39, 27, -45, 5, 49, 55, -6, 6, 9, 11, 4, 29, -4, -6, -17, -55, 7, 15, 0, 14, 7, 40, -34, 9, 39, 28, 43, -11, -128, -36, 23, 3, -31, 28, 30, -14, 1, -40, 5, 14, 25, -52, -17, 16, 15, 14, -43, 90, -32, -43, 27, -20, -31, -3, -57, 25, 70, -32, 37, -25, -19, 67, 2, 53, 10, -24, -9, 78, -20, -19, 30, -35, -31, -35, -25, 19, -70, 25, 18, -18, 8, -31, 12, 118, -27, 43, 24, 14, 5, 49, -66, 21, -32, -40, 14, 51, 34, 72, 36, -38, 23, 0, -20, -19, 4, -32, -60, 52, 29, 21, 0, 40, 81, 24, 88, 7, -45, -29, -83, -37, -39, 41, -9, -34, 35, -7, 19, -19, -10, 0, -39, 34, -97, -27, -35, -14, 28, 44, -7, 14, -32, -24, 26, -30, 13, 62, 7, 13, 65, 61, 106, -41, 52, -86, 70, 0, -18, 62, -76, -16, 11, -69, -10, 31, -15, 60, 13, -44, -13, 0, 6, 19, 7, -24, -1, -27, -42, 66, 30, -1, 1, -9, -60, 2, -1, -48, 8, 78, -25, -62, -57, 29, -41, 46, -36, 42, -79, -19, -10, -32, 6, -20, -18, -12, 45, 10, 22, -52, 1, 10, 37, 50, -25, -15, -50, 13, -22, -29, 44, -74, -49, 20, 45, -18, 50, -42, -53, 25, 35, 46, -30, -38, 75, 12, 127, 22, -10, 10, 59, -42, -11, 22, 44, -19, 7, 17, 10, -27, 13, -12, 43, -22, -108, 72, -1, 0, -37, -29, 5, 49, -15, -12, 77, -51, -91, -49, -45, -10, -15, -30, 27, 16, -47, -40, 8, 11, 20, -17, -18, -35, 13, -8, -5, 4, 80, 45, 21, 34, -44, 39, -22, -54, -11, -9, -37, -27, 8, 6, -4, 3, -24, -64, 43, 57, 2, 9, -12, 127, -66, 21, -30, -9, -42, -43, -22, 50, -44, 60, 25, 81, -35, 37, 53, 31, -23, 43, -38, 43, -40, 12, -18, 1, 0, 3, -52, -45, 8, 46, -16, 38], [-47, -19, -105, 29, -31, -72, 0, 6, -53, 69, 54, 17, 0, -38, -10, 10, -44, 68, 20, -16, -2, -44, -19, -128, 33, -4, -64, 21, -23, -8, 12, 21, 28, 55, -52, 39, 0, 24, -1, 31, 1, 4, 28, 2, -29, 19, -33, -47, 27, -36, -29, -28, 5, -41, -40, -60, 43, -21, 49, -92, -60, -22, 59, 65, 36, -11, 26, 36, -77, 32, 36, -58, -4, -13, -48, 5, 12, -7, 18, -15, -36, 48, -7, -35, -29, -15, -41, -18, -72, -38, -39, 35, -128, 19, 44, -27, -7, 15, 1, 16, -21, -23, 1, -38, -31, 86, 61, 81, -17, 5, 2, -39, 40, -76, -21, 26, 24, 48, 56, 42, 26, 98, -37, -16, 41, 51, 15, -61, -24, -19, -34, 48, 60, 19, -15, 0, 28, -16, 27, 12, 50, -46, 13, 47, -8, 9, 18, 15, 20, -25, 8, -25, -22, 13, -5, 7, -28, -4, 32, 21, 38, 16, 16, -1, -14, -31, -32, 13, 9, 47, 8, -5, -60, -39, -35, -14, -10, -10, -64, 127, 93, -48, -118, 63, 58, -70, 21, -58, -31, 36, -21, 33, 0, 1, -21, -27, -17, 11, -17, 1, -50, 63, -39, 53, 11, 24, -11, 33, 0, 0, -5, -36, 23, -52, -10, 31, -8, 2, -30, -1, -8, 6, -33, 42, 34, 27, -35, 7, 38, 20, 8, 29, 10, -12, -32, 33, 103, -15, 0, 9, 29, -66, -45, -18, 69, 65, 27, -22, 27, 60, -35, -48, 12, -85, -29, 50, 51, 70, -25, 26, -50, 72, 11, -1, -58, 62, 13, 29, -30, 7, 32, 41, -13, 60, -38, 57, -26, 0, -5, 48, 16, 64, 36, -11, 19, 58, 18, -8, -19, -40, 26, 6, 10, -9, 0, -30, 18, 73, 2, -31, -75, -32, -43, -44, 38, -18, 25, -3, 31, 32, -66, 35, 21, -38, 20, -36, -42, -6, -71, -11, -76, -57, 16, -51, -20, 28, -60, 34, 6, -2, 103, 57, 47, 4, 32, -38, -4, 32, -26, -4, -27, -57, -10, -47, -58, 62, 1, 18, -27, 19, -28, -30, 26, 46, 13, -18, -19, 53, -32, -27, -47, 13, -39, 0, 15, -15, -10, 29, 33, -5, 26, -21, -3, -15, 27, -46, 5, -40, 51, 22, 12, 0, 14, -16, 56, -28, -68, -22, 61, 52, 21, -29, 52, -26, -25, -29, -33, 34, -30, 39, 14, -17, -30, 20, -44, 5, 5, -30, 15, 34, -38, -62, -55, -73, 7, 2, -99, -33, 72, 36, -85, 71, -68, 51, -8, 3, 2, -10, 60, 62, 19, 5, -17, 5, 19, 9, -21, -25, 10, -20, 68, 3, -18, 60, -10, -2, -4, 20, 17, -7, 34, -12, 30, 20, -48, 73, 73, 29, 15, 91, 35, 19, -13, 0, -44, 12, 44, 8, -31, -3, -18, 34, -2, 51, 2, 101, -36, 44, -113, 32, -65, 36, 20, -50, -63, 32, -75, -69, 12, 0, -67, -1, 34, -19, 3, 39, -12, 37, 8, -54, -6, 0, 26, 21, 7, -7, -9, 3, -15, 18, -37, -18, 77, -18, 16, -31, 112, -43, 54, -5, -9, -12, 55, 19, -8, -39, 61, -10, -14, 4, 56, 33, 31, 3, -24, -47, -14, -32, 13, 9, 11, 3, -46, 37, -9, 40, -47, 27, -1, 59, -49, -80, 49, -32, -17, -44, 13, -40, 3, 17, 32, 17, -23, -39, 32, 11, -37, -86, 117, -81, -52, -58, -2, -24, 40, 12, 10, 23, 17, 18, 8, 28, 0, 27, 7, -21, 8, -39, 8, -31, -13, -15, 27, -82, -18, -21, -28, -15, -5, 0, 22, 16, 0, -14, -34, 22, 62, 34, 3, 40, -13, -65, 31, -2, 31, 10, -5, 24, -84, -6, -14, -37, 15, -76, -39, -26, -20, -73, -64, 10, -84, 10, -46, -92, -30, 78, -8, -44, -2, 38, 33, 19, -12, -35, -4, 0, -23, -12, -16, 5, 1, 4, -11, -11, 12, 14, -41, 50, 1, 6, -38, 49, 5, -6, -30, 49, 81, 54, 8, -2, 8, 69, -13, -43, 10, 25, 16, 15, 9, -61, -4, -7, 55, -34, -20, 13, 11, 8, 21, 0, 8, 43, -14, 28, 54, 30, -38, -47, 14, 22, 8, -22, 22, -33, -7, 21, 15, -5, -3, -12, 6, 47, -16, -8, 35, -45, -31, -40, -71, 22, -40, 23, 7, -36, 7, 23, -62, 14, 20, 41, -34, 53, -25, -45, 27, -22, 8, 42, 35, -3, 40, -32, 64, -13, 27, 60, 7, 87, 61, 43, 16, 43, -3, 4, 34, -3, 10, -39, -20, -8, -71, 10, 5, 44, -9, 40, -44, 6, -1, 0, -44, 64, -11, -4, -35, -31, 14, -32, -19, -17, 9, 0, 15, 12, -1, 9, 50, -5, -19, -8, 29, 47, -40, -1, -4, 38, 14, -8, 85, -15, -14, -94, -6, -25, 6, 26, -29, 12, 10, 45, 4, -36, 9, -18, 108, 34, -73, -9, -56, -54, 54, 53, -28, 33, 37, -6, 5, 6, -1, 26, 39, 13, -29, -24, 54, 12, 0, -128, 95, 0, -37, 40, -91, -7, -46, -23, 36, 11, 30, 25, 25, -50, -102, 45, 20, 58, 12, -41, -78, -36, 27, -10, 31, 18, 2, -108, -50, -60, -19, -128, 4, 76, 9, -72, -35, 7, 6, -50, -6, 10, -102, -68, -1, -11, 2, -95, 19, -10, 34, -22, 48, 12, 8, 78, 33, 8, -58, -14, -31, 29, -36, 3, -38, -41, 4, -12, -11, -40, 1, -32, 24, 30, 70, 48, -37, -10, 127, 61, 127, -4, -19, 30, 5, -9, -29, 9, -57, -7, 6, -16, -16, -26, 9, 47, 34, -3, 2, 18, 11, 32, 1, 20, -31, -22, 25, 8, 52, 4, -24, 45, 41, 31, -75, 14, -26, -32, -45, -28, 41, 64, 37, 11, 17, -35, -42, -59, -11, 40, 46, 4, -1, 0, -31, 20, -15, -58, 18, -18, 16, 51, -35, 44, -61, 15, 9, 1, -22, -15, -12, 5, -21, 13, 8, 31, 12, 10, 62, -45, 35, 24, 3, 0, -19, 0, 10, -11, -45, 36, -10, -90, -48, 40, 11, -32, -7, -27, -13, -23, -68, -34, -7, -15, -34, 16]]\n","\tuint8: None\n","\tbinary: [[-110, 121, 110, -50, 87, -59, 8, 35, 114, 30, -92, -112, -118, -16, 7, 96, 17, 19, 97, -9, -23, 25, -103, -35, -78, -47, 64, -123, -41, 67, 14, -31, -42, -126, 75, 111, 62, -64, 57, 64, -52, -66, -64, -12, 100, 99, 87, 61, -5, 5, 23, 34, -75, -66, -16, 91, 92, 121, 55, 117, 100, -112, -24, 84, 84, -65, -67, -31, -45, 7, 44, 8, -35, -125, 16, -50, -52, 11, -105, -32, 102, -62, -3, 86, -107, 21, 95, 15, 27, -79, -20, 114, 90, 125, 110, -97, -15, -98, 21, -102, -124, 112, -115, 26, -86, -55, 67, 7, 11, -127, 125, 103, -46, -55, 79, -31, 126, -32, 33, -128, -124, -80, 21, 27, -49, -9, 112, 101], [-112, -7, -24, 23, -33, 68, 24, 35, 22, -50, -32, 86, 74, -14, 71, 96, 81, -46, 105, -25, -73, 108, -99, 13, -76, 125, 73, -44, -34, -34, -105, 75, 86, -58, 85, -30, -92, -27, -39, 0, -91, -2, 30, -12, -116, 9, 81, 39, 76, 44, 87, 20, -43, 110, -75, 20, 108, 125, -75, 85, -28, -118, -24, 127, 78, -75, 108, -20, -48, 3, 12, 12, 71, -29, -98, -26, 68, 11, 0, -104, 96, 70, -3, 53, -98, -108, 127, -102, -17, -84, -88, 88, -54, -45, -11, -4, -4, 15, -67, 122, -108, 117, -115, -88, 98, -47, 102, -103, 3, -123, -85, 119, -48, -24, 95, -34, -26, -24, -31, -9, 99, 64, -128, -43, 74, -91, 80, -95], [64, -14, -4, 30, 118, 5, 8, 35, 51, 3, 72, -122, -70, -10, 2, -20, 17, 115, -67, -11, 115, 31, -103, -73, -78, 65, 64, -123, -41, 91, 14, -39, -41, -78, 73, -62, 60, -28, 89, 32, 33, -35, -62, 116, 102, -45, 83, 63, 73, 37, 23, 64, -43, -46, -106, 83, 109, 92, -87, -15, -60, -39, -23, 63, 84, 56, -6, -15, 20, 3, 76, 3, 104, -16, -79, 70, -123, 15, -125, -111, 109, -105, -99, 82, -19, -27, 95, -113, 94, -74, 57, 82, -102, -7, -95, -21, -3, -66, 9, 95, -124, 37, -115, -81, 107, -55, -25, 6, 19, -107, -120, 111, -110, -23, 79, -26, 106, -45, -96, -77, 9, 116, -115, -67, -63, -9, -43, 77], [-109, -7, -32, 19, 85, 116, 8, 35, 54, -102, -64, -106, -14, -10, 31, 78, -99, 59, -6, -45, 97, 96, -103, 37, 69, -35, 73, -59, 95, 27, 14, 73, 86, -9, -43, 110, -70, 96, 45, 32, -91, 62, -64, -12, 100, -39, 34, 62, 14, 5, 22, 67, -75, -17, -14, 81, 45, 124, -15, -11, -28, 75, -25, 20, 42, -78, -4, -67, -44, 11, 76, 3, 127, 40, 1, 103, 75, -62, -123, -111, 68, -13, -10, -5, -66, -89, 119, -70, -29, -95, -19, 82, 106, 127, -24, -11, -48, 15, -29, -102, -115, 107, -115, 55, -69, -61, 103, 11, 3, 25, -118, 63, -108, 11, 78, -28, 14, 124, 119, -61, 97, 84, 53, 69, 123, 25, -104, -127]]\n","\tubinary: None\n","}\n","\tmeta: {'api_version': {'version': '1'}, 'billed_units': {'input_tokens': 106}}\n","}\n"]}],"source":["print(embeddings)"]},{"cell_type":"markdown","id":"72ec8cf4","metadata":{},"source":["As we can see from the above, we got multiple vector representations for the same input strings. "]},{"cell_type":"code","execution_count":54,"id":"20baafcb","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["int8 dimensionality: 1024, binary dimensionality 128\n"]}],"source":["print(\"int8 dimensionality: {}, binary dimensionality {}\".format(\n","  len(embeddings.embeddings.int8[0]), len(embeddings.embeddings.binary[0])))"]},{"cell_type":"markdown","id":"74ec69ca","metadata":{"id":"da356d25"},"source":["## Definining the Vespa application\n","\n","First, we define a [Vespa schema](https://docs.vespa.ai/en/schemas.html) with the fields we want to store and their type. \n","\n","Notice the `binary_vector` field that defines an indexed (dense) Vespa tensor with the dimension name `x[128]`. \n","\n","Indexing specifies `index` which means that Vespa will build HNSW graph for searching this vector field. \n","\n","Also, notice the configuration of the [distance-metric](https://docs.vespa.ai/en/reference/schema-reference.html#distance-metric). \n","\n","We also want to store the `int8_vector` on disk; we use `paged` to signalize this. "]},{"cell_type":"code","execution_count":9,"id":"29105961","metadata":{"executionInfo":{"elapsed":224,"status":"ok","timestamp":1706652002196,"user":{"displayName":"Andreas Eriksen","userId":"00161553861396505040"},"user_tz":-60},"id":"0dca2378"},"outputs":[],"source":["from vespa.package import Schema, Document, Field, FieldSet\n","my_schema = Schema(\n","            name=\"doc\",\n","            mode=\"index\",\n","            document=Document(\n","                fields=[\n","                    Field(name=\"doc_id\", type=\"string\", indexing=[\"summary\"]),\n","                    Field(name=\"text\", type=\"string\", indexing=[\"summary\", \"index\"], index=\"enable-bm25\"),\n","                    Field(name=\"binary_vector\", type=\"tensor<int8>(x[128])\",\n","                        indexing=[\"attribute\", \"index\"],\n","                        attribute=[\"distance-metric: hamming\"]\n","                    ),\n","                    Field(name=\"int8_vector\", type=\"tensor<int8>(x[1024])\",\n","                        indexing=[\"attribute\"],\n","                        attribute=[\"paged\"]\n","                    )\n","                ]\n","            ),\n","            fieldsets=[\n","                FieldSet(name = \"default\", fields = [\"text\"])\n","            ]\n",")"]},{"cell_type":"markdown","id":"bed768cb","metadata":{},"source":["\n","\n","We must add the schema to a Vespa [application package](https://docs.vespa.ai/en/application-packages.html).\n","This consists of configuration files, schemas, models, and possibly even custom code (plugins)."]},{"cell_type":"code","execution_count":10,"id":"c371b01f","metadata":{"executionInfo":{"elapsed":239,"status":"ok","timestamp":1706652007584,"user":{"displayName":"Andreas Eriksen","userId":"00161553861396505040"},"user_tz":-60},"id":"66c5da1d"},"outputs":[],"source":["from vespa.package import ApplicationPackage\n","\n","vespa_app_name = \"cohere\"\n","vespa_application_package = ApplicationPackage(\n","        name=vespa_app_name,\n","        schema=[my_schema]\n",")"]},{"cell_type":"markdown","id":"9a3fe087","metadata":{"id":"7fe3d7bd"},"source":["In the last step, we configure [ranking](https://docs.vespa.ai/en/ranking.html) by adding `rank-profile`'s to the schema.\n","\n","`unpack_bits`, unpacks the binary representation into a 1024-dimensional float vector [doc](https://docs.vespa.ai/en/reference/ranking-expressions.html#unpack-bits). \n","\n","\n","We define three tensor inputs that we intend to send with the query request. "]},{"cell_type":"code","execution_count":38,"id":"a5d13c7f","metadata":{"executionInfo":{"elapsed":407,"status":"ok","timestamp":1706652010412,"user":{"displayName":"Andreas Eriksen","userId":"00161553861396505040"},"user_tz":-60},"id":"a8ce5624"},"outputs":[],"source":["from vespa.package import RankProfile, FirstPhaseRanking, SecondPhaseRanking\n","\n","\n","rerank = RankProfile(\n","    name=\"rerank\",\n","    inputs=[\n","        (\"query(q_binary)\", \"tensor<int8>(x[128])\"),\n","        (\"query(q_full)\", \"tensor<float>(x[1024])\"),\n","        (\"query(q_int8)\", \"tensor<int8>(x[1024])\")\n","        ],\n","    first_phase=FirstPhaseRanking(\n","        expression=\"sum(query(q_full)*unpack_bits(attribute(binary_vector)))\" # phase 1 ranking using the float query the unpacked float version of the binary_vector\n","    ),\n","    second_phase=SecondPhaseRanking(\n","        expression=\"cosine_similarity(query(q_int8),attribute(int8_vector),x)\", # phase 2 using the int8 vector representations\n","        rerank_count=30 # number of hits to rerank, upper bound on number of random IO operations\n","    ),\n","    match_features=[\"distance(field, binary_vector)\", \"closeness(field, binary_vector)\", \"firstPhase\"],  \n",")\n","my_schema.add_rank_profile(rerank)"]},{"cell_type":"markdown","id":"c46c95aa","metadata":{"id":"846545f9"},"source":["## Deploy the application to Vespa Cloud\n","\n","With the configured application, we can deploy it to [Vespa Cloud](https://cloud.vespa.ai/en/).\n","It is also possible to deploy the app using docker; see the [Hybrid Search - Quickstart](https://pyvespa.readthedocs.io/en/latest/getting-started-pyvespa.html) guide for\n","an example of deploying it to a local docker container."]},{"cell_type":"markdown","id":"cf82b02d","metadata":{"id":"16179d9b"},"source":["Install the Vespa CLI using [homebrew](https://brew.sh/) - or download a binary from GitHub as demonstrated below."]},{"cell_type":"code","execution_count":null,"id":"1f1337cf","metadata":{"id":"343981ce"},"outputs":[],"source":["!brew install vespa-cli"]},{"cell_type":"markdown","id":"b64966d7","metadata":{"id":"863d0700"},"source":["Alternatively, if running in Colab, download the Vespa CLI:"]},{"cell_type":"code","execution_count":null,"id":"89b92fa2","metadata":{"executionInfo":{"elapsed":1410,"status":"ok","timestamp":1706648103221,"user":{"displayName":"Andreas Eriksen","userId":"00161553861396505040"},"user_tz":-60},"id":"d5670bb6"},"outputs":[],"source":["import os\n","import requests\n","res = requests.get(url=\"https://api.github.com/repos/vespa-engine/vespa/releases/latest\").json()\n","os.environ[\"VERSION\"] = res[\"tag_name\"].replace(\"v\", \"\")\n","!curl -fsSL https://github.com/vespa-engine/vespa/releases/download/v${VERSION}/vespa-cli_${VERSION}_linux_amd64.tar.gz | tar -zxf -\n","!ln -sf /content/vespa-cli_${VERSION}_linux_amd64/bin/vespa /bin/vespa"]},{"cell_type":"markdown","id":"b996a9d7","metadata":{"id":"0ff00727"},"source":["To deploy the application to Vespa Cloud we need to create a tenant in the Vespa Cloud:\n","\n","Create a tenant at [console.vespa-cloud.com](https://console.vespa-cloud.com/) (unless you already have one).\n","This step requires a Google or GitHub account, and will start your [free trial](https://cloud.vespa.ai/en/free-trial).\n","Make note of the tenant name, it is used in the next steps."]},{"cell_type":"markdown","id":"8b1d2950","metadata":{"id":"df9f9a1c"},"source":["### Configure Vespa Cloud date-plane security\n","\n","Create Vespa Cloud data-plane mTLS cert/key-pair. The mutual certificate pair is used to talk to your Vespa cloud endpoints. See [Vespa Cloud Security Guide](https://cloud.vespa.ai/en/security/guide) for details.\n","\n","We save the paths to the credentials for later data-plane access without using pyvespa APIs."]},{"cell_type":"code","execution_count":null,"id":"b9d9545c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":611,"status":"ok","timestamp":1706648115118,"user":{"displayName":"Andreas Eriksen","userId":"00161553861396505040"},"user_tz":-60},"id":"b6a766d6","outputId":"47075852-89e2-41a8-cb96-af10dbe534d7"},"outputs":[],"source":["import os\n","\n","os.environ[\"TENANT_NAME\"] = \"vespa-team\" # Replace with your tenant name\n","\n","vespa_cli_command = f'vespa config set application {os.environ[\"TENANT_NAME\"]}.{vespa_app_name}'\n","\n","!vespa config set target cloud\n","!{vespa_cli_command}\n","!vespa auth cert -N"]},{"cell_type":"markdown","id":"e10487bd","metadata":{"id":"b228381b"},"source":["Validate that we have the expected data-plane credential files:"]},{"cell_type":"code","execution_count":16,"id":"70abcc3b","metadata":{"executionInfo":{"elapsed":241,"status":"ok","timestamp":1706648119995,"user":{"displayName":"Andreas Eriksen","userId":"00161553861396505040"},"user_tz":-60},"id":"1f0b97c8"},"outputs":[],"source":["from os.path import exists\n","from pathlib import Path\n","\n","cert_path = Path.home() / \".vespa\" / f\"{os.environ['TENANT_NAME']}.{vespa_app_name}.default/data-plane-public-cert.pem\"\n","key_path = Path.home() / \".vespa\" / f\"{os.environ['TENANT_NAME']}.{vespa_app_name}.default/data-plane-private-key.pem\"\n","\n","if not exists(cert_path) or not exists(key_path):\n","    print(\"ERROR: set the correct paths to security credentials. Correct paths above and rerun until you do not see this error\")"]},{"cell_type":"markdown","id":"fd7b4049","metadata":{"id":"85ce80e0"},"source":["Note that the subsequent Vespa Cloud deploy call below will add `data-plane-public-cert.pem` to the application before deploying it to Vespa Cloud, so that\n","you have access to both the private key and the public certificate. At the same time, Vespa Cloud only knows the public certificate.\n","\n","### Configure Vespa Cloud control-plane security\n","\n","Authenticate to generate a tenant level control plane API key for deploying the applications to Vespa Cloud, and save the path to it.\n","\n","The generated tenant api key must be added in the Vespa Console before attemting to deploy the application.\n","\n","```\n","To use this key in Vespa Cloud click 'Add custom key' at\n","https://console.vespa-cloud.com/tenant/TENANT_NAME/account/keys\n","and paste the entire public key including the BEGIN and END lines.\n","```"]},{"cell_type":"code","execution_count":null,"id":"e4de9e4e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":244,"status":"ok","timestamp":1706648129288,"user":{"displayName":"Andreas Eriksen","userId":"00161553861396505040"},"user_tz":-60},"id":"5bf8731c","outputId":"5f615d4c-9469-4be8-c8fe-9d0fc9dab4f6"},"outputs":[],"source":["!vespa auth api-key\n","\n","from pathlib import Path\n","api_key_path = Path.home() / \".vespa\" / f\"{os.environ['TENANT_NAME']}.api-key.pem\""]},{"cell_type":"markdown","id":"52fe7b5d","metadata":{"id":"21db1010"},"source":["### Deploy to Vespa Cloud\n","\n","Now that we have data-plane and control-plane credentials ready, we can deploy our application to Vespa Cloud!\n","\n","`PyVespa` supports deploying apps to the [development zone](https://cloud.vespa.ai/en/reference/environments#dev-and-perf).\n","\n",">Note: Deployments to dev and perf expire after 7 days of inactivity, i.e., 7 days after running deploy. This applies to all plans, not only the Free Trial. Use the Vespa Console to extend the expiry period, or redeploy the application to add 7 more days."]},{"cell_type":"code","execution_count":39,"id":"3a11f211","metadata":{"executionInfo":{"elapsed":339,"status":"ok","timestamp":1706652019048,"user":{"displayName":"Andreas Eriksen","userId":"00161553861396505040"},"user_tz":-60},"id":"b5fddf9f"},"outputs":[],"source":["from vespa.deployment import VespaCloud\n","\n","def read_secret():\n","    \"\"\"Read the API key from the environment variable. This is\n","    only used for CI/CD purposes.\"\"\"\n","    t = os.getenv(\"VESPA_TEAM_API_KEY\")\n","    if t:\n","        return t.replace(r\"\\n\", \"\\n\")\n","    else:\n","        return t\n","\n","vespa_cloud = VespaCloud(\n","    tenant=os.environ[\"TENANT_NAME\"],\n","    application=vespa_app_name,\n","    key_content=read_secret() if read_secret() else None,\n","    key_location=api_key_path,\n","    application_package=vespa_application_package)"]},{"cell_type":"markdown","id":"cc1c140a","metadata":{"id":"fa9baa5a"},"source":["Now deploy the app to Vespa Cloud dev zone.\n","\n","The first deployment typically takes 2 minutes until the endpoint is up."]},{"cell_type":"code","execution_count":null,"id":"494f5144","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12057,"status":"ok","timestamp":1706652033883,"user":{"displayName":"Andreas Eriksen","userId":"00161553861396505040"},"user_tz":-60},"id":"fe954dc4","outputId":"6150363c-cfac-4240-e790-f84f98c481b0"},"outputs":[],"source":["from vespa.application import Vespa\n","app:Vespa = vespa_cloud.deploy()"]},{"cell_type":"markdown","id":"abc3be8f","metadata":{"id":"54db44b1"},"source":["## Feed our sample documents and their binary embedding representation\n","\n","With few documents, we use the synchronous API.  Read more in [reads and writes](https://pyvespa.readthedocs.io/en/latest/reads-writes.html).\n"]},{"cell_type":"code","execution_count":41,"id":"00aad720","metadata":{},"outputs":[],"source":["for i, doc in enumerate(documents):\n","    response = app.feed_data_point(\n","        schema=\"doc\",\n","        data_id=str(i),\n","        fields={\n","            \"doc_id\": str(i),\n","            \"text\": doc,\n","            \"binary_vector\": embeddings.embeddings.binary[i],\n","            \"int8_vector\": embeddings.embeddings.int8[i]\n","        }\n","    )\n","    assert response.is_successful()"]},{"cell_type":"markdown","id":"c39b1f1a","metadata":{"id":"20b007ec"},"source":["### Querying data\n","\n","\n","Read more about querying Vespa in:\n","\n","- [Vespa Query API](https://docs.vespa.ai/en/query-api.html)\n","- [Vespa Query API reference](https://docs.vespa.ai/en/reference/query-api-reference.html)\n","- [Vespa Query Language API (YQL)](https://docs.vespa.ai/en/query-language.html)\n","- [Practical Nearest Neighbor Search Guide](https://docs.vespa.ai/en/nearest-neighbor-search-guide.html)\n","\n","We now need to invoke the embed API again to embed the query text; we ask for all three representations:"]},{"cell_type":"code","execution_count":30,"id":"377da3d7","metadata":{},"outputs":[],"source":["query = \"Who discovered x-ray?\"\n","\n","# Make sure to set input_type=\"search_query\" when getting the embeddings for the query.\n","# We ask for 3 versions (float, binary, and int8) of the embeddings.\n","query_emb = co.embed(\n","  [query], \n","  model=\"embed-english-v3.0\", \n","  input_type=\"search_query\", \n","  embedding_types=[\"float\",\"binary\", \"int8\"])"]},{"cell_type":"code","execution_count":null,"id":"b395304c","metadata":{},"outputs":[],"source":["print(query_emb)"]},{"cell_type":"markdown","id":"2d086ade","metadata":{},"source":["Now, we use Vespa's [nearestNeighbor](https://docs.vespa.ai/en/reference/query-language-reference.html#nearestneighbor) query operator\n","to expose up to 1000 hits to ranking using the configured distance-metric (hamming distance). \n","\n","This is the retrieve logic,  or phase-0 search as it only uses the hamming distance. See [phased ranking](https://docs.vespa.ai/en/phased-ranking.html) for more\n","on phased ranking pipelines.\n","\n","The hits that are near in hamming space, are exposed to the flexibility of the Vespa ranking framework:\n","\n","- the first-phase uses the unpacked version of the binary vector and computes the dot product against the float query version\n","- The second phase and final phase re-ranks the 30 best from the the previous phase, here using cosine similarity between the int8 embedding representations "]},{"cell_type":"code","execution_count":47,"id":"686f1cf0","metadata":{},"outputs":[],"source":["response = app.query(\n","  yql=\"select * from doc where {targetHits:1000}nearestNeighbor(binary_vector,q_binary)\", \n","  ranking=\"rerank\",\n","  body = {\n","  'input.query(q_binary)': query_emb.embeddings.binary[0],\n","  'input.query(q_full)': query_emb.embeddings.float[0],\n","  'input.query(q_int8)': query_emb.embeddings.int8[0]\n","  }\n",")\n","assert response.is_successful()"]},{"cell_type":"code","execution_count":48,"id":"7f84d4c6","metadata":{},"outputs":[{"data":{"text/plain":["[{'id': 'id:doc:doc::3',\n","  'relevance': 0.45650564242263414,\n","  'source': 'cohere_content',\n","  'fields': {'matchfeatures': {'closeness(field,binary_vector)': 0.0030303030303030303,\n","    'distance(field,binary_vector)': 329.0,\n","    'firstPhase': 4.905200004577637},\n","   'sddocname': 'doc',\n","   'documentid': 'id:doc:doc::3',\n","   'doc_id': '3',\n","   'text': 'Marie Curie was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity'}},\n"," {'id': 'id:doc:doc::1',\n","  'relevance': 0.337421116422118,\n","  'source': 'cohere_content',\n","  'fields': {'matchfeatures': {'closeness(field,binary_vector)': 0.002544529262086514,\n","    'distance(field,binary_vector)': 391.99999999999994,\n","    'firstPhase': 3.7868080139160156},\n","   'sddocname': 'doc',\n","   'documentid': 'id:doc:doc::1',\n","   'doc_id': '1',\n","   'text': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time.'}},\n"," {'id': 'id:doc:doc::2',\n","  'relevance': 0.280400768492745,\n","  'source': 'cohere_content',\n","  'fields': {'matchfeatures': {'closeness(field,binary_vector)': 0.0026595744680851063,\n","    'distance(field,binary_vector)': 375.0,\n","    'firstPhase': 3.854860305786133},\n","   'sddocname': 'doc',\n","   'documentid': 'id:doc:doc::2',\n","   'doc_id': '2',\n","   'text': 'Isaac Newton was an English polymath active as a mathematician, physicist, astronomer, alchemist, theologian, and author who was described in his time as a natural philosopher.'}},\n"," {'id': 'id:doc:doc::0',\n","  'relevance': 0.2570603626828106,\n","  'source': 'cohere_content',\n","  'fields': {'matchfeatures': {'closeness(field,binary_vector)': 0.0024390243902439024,\n","    'distance(field,binary_vector)': 409.0,\n","    'firstPhase': 2.845644474029541},\n","   'sddocname': 'doc',\n","   'documentid': 'id:doc:doc::0',\n","   'doc_id': '0',\n","   'text': 'Alan Turing  was an English mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist.'}}]"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["response.hits"]},{"cell_type":"markdown","id":"bb8922bc","metadata":{},"source":["The `relevance` is the cosine similarity between the int8 vector representations calculated in the second-phase. Note also that we return the `hamming` distance\n","and the firstPhase score which is the query, unpacked binary dot product. "]},{"cell_type":"markdown","id":"9b9f45d3","metadata":{"id":"7c8b8223"},"source":["## Conclusions\n","\n","These new Cohere binary embeddings are a huge step forward for cost-efficient vector search at scale and integrate perfectly\n","with Vespa features for building out vector search at scale. \n","\n","Storing the `int8` vector representation on disk using the paged attribute option enables phased retrieval and ranking close to the data. \n","First, one can use the compact in-memory binary representation for the coarse-level search to efficiently find a limited number of candidates. \n","Then, the candidates from the coarse search can be re-scored and re-ranked using a more advanced scoring function using a finer resolution. \n","\n","\n","\n","### Clean up\n","We can now delete the cloud instance:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3720,"status":"ok","timestamp":1705505103257,"user":{"displayName":"Andreas Eriksen","userId":"00161553861396505040"},"user_tz":-60},"id":"71e310e3","outputId":"991b1965-6c33-4985-e873-a92c43695528"},"outputs":[],"source":["vespa_cloud.delete()"]}],"metadata":{"colab":{"name":"","provenance":[{"file_id":"1FoVAybR6dhXy-uDkVuDfBtVzSJoresCB","timestamp":1706644027750}],"version":""},"kernelspec":{"display_name":"Python 3.11.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"vscode":{"interpreter":{"hash":"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}}},"nbformat":4,"nbformat_minor":5}
