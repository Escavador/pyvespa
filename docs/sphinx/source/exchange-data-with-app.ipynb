{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-friendly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for configuration server, 0/300 seconds...\n",
      "Waiting for configuration server, 5/300 seconds...\n",
      "Waiting for configuration server, 10/300 seconds...\n",
      "Waiting for application status, 0/300 seconds...\n",
      "Waiting for application status, 5/300 seconds...\n",
      "Waiting for application status, 10/300 seconds...\n",
      "Waiting for application status, 15/300 seconds...\n",
      "Waiting for application status, 20/300 seconds...\n",
      "Waiting for application status, 25/300 seconds...\n",
      "Waiting for application status, 30/300 seconds...\n",
      "Finished deployment.\n"
     ]
    }
   ],
   "source": [
    "# this is a hidden cell. It will not show on the documentation HTML.\n",
    "import os\n",
    "from vespa.package import (\n",
    "    HNSW,\n",
    "    Document,\n",
    "    Field,\n",
    "    Schema,\n",
    "    FieldSet,\n",
    "#    SecondPhaseRanking,\n",
    "    RankProfile,\n",
    "    ApplicationPackage,\n",
    "    QueryProfile,\n",
    "    QueryProfileType,\n",
    "    QueryTypeField\n",
    ")\n",
    "\n",
    "from vespa.deployment import VespaDocker\n",
    "\n",
    "class QuestionAnswering(ApplicationPackage):\n",
    "    def __init__(self, name: str = \"qa\"):\n",
    "        context_document = Document(\n",
    "            fields=[\n",
    "                Field(\n",
    "                    name=\"questions\",\n",
    "                    type=\"array<int>\",\n",
    "                    indexing=[\"summary\", \"attribute\"],\n",
    "                ),\n",
    "                Field(name=\"dataset\", type=\"string\", indexing=[\"summary\", \"attribute\"]),\n",
    "                Field(name=\"context_id\", type=\"int\", indexing=[\"summary\", \"attribute\"]),\n",
    "                Field(\n",
    "                    name=\"text\",\n",
    "                    type=\"string\",\n",
    "                    indexing=[\"summary\", \"index\"],\n",
    "                    index=\"enable-bm25\",\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        context_schema = Schema(\n",
    "            name=\"context\",\n",
    "            document=context_document,\n",
    "            fieldsets=[FieldSet(name=\"default\", fields=[\"text\"])],\n",
    "            rank_profiles=[\n",
    "                RankProfile(name=\"bm25\", inherits=\"default\", first_phase=\"bm25(text)\"),\n",
    "                RankProfile(\n",
    "                    name=\"nativeRank\",\n",
    "                    inherits=\"default\",\n",
    "                    first_phase=\"nativeRank(text)\",\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "        sentence_document = Document(\n",
    "            inherits=\"context\",\n",
    "            fields=[\n",
    "                Field(\n",
    "                    name=\"sentence_embedding\",\n",
    "                    type=\"tensor<float>(x[512])\",\n",
    "                    indexing=[\"attribute\", \"index\"],\n",
    "                    ann=HNSW(\n",
    "                        distance_metric=\"euclidean\",\n",
    "                        max_links_per_node=16,\n",
    "                        neighbors_to_explore_at_insert=500,\n",
    "                    ),\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "        sentence_schema = Schema(\n",
    "            name=\"sentence\",\n",
    "            document=sentence_document,\n",
    "            fieldsets=[FieldSet(name=\"default\", fields=[\"text\"])],\n",
    "            rank_profiles=[\n",
    "                RankProfile(\n",
    "                    name=\"semantic-similarity\",\n",
    "                    inherits=\"default\",\n",
    "                    first_phase=\"closeness(sentence_embedding)\",\n",
    "                ),\n",
    "                RankProfile(name=\"bm25\", inherits=\"default\", first_phase=\"bm25(text)\"),\n",
    "                RankProfile(\n",
    "                    name=\"bm25-semantic-similarity\",\n",
    "                    inherits=\"default\",\n",
    "                    first_phase=\"bm25(text) + closeness(sentence_embedding)\",\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            schema=[context_schema, sentence_schema],\n",
    "            query_profile=QueryProfile(),\n",
    "            query_profile_type=QueryProfileType(\n",
    "                fields=[\n",
    "                    QueryTypeField(\n",
    "                        name=\"ranking.features.query(query_embedding)\",\n",
    "                        type=\"tensor<float>(x[512])\",\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "app_package = QuestionAnswering()\n",
    "vespa_docker = VespaDocker()\n",
    "app = vespa_docker.deploy(application_package=app_package)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-subsection",
   "metadata": {},
   "source": [
    "# Exchange data with applications\n",
    "\n",
    "> Feed, get, update and delete operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-biography",
   "metadata": {},
   "source": [
    "We will use the [question answering (QA) app](https://pyvespa.readthedocs.io/en/latest/examples/semantic-retrieval-for-question-answering-applications.html) to demonstrate ways to feed data to an application. We start by downloading sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-amazon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'dataset', 'questions', 'context_id', 'sentence_embedding']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, requests\n",
    "\n",
    "sentence_data = json.loads(\n",
    "    requests.get(\"https://data.vespa.oath.cloud/blog/qa/sample_sentence_data_100.json\").text\n",
    ")\n",
    "list(sentence_data[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-milan",
   "metadata": {},
   "source": [
    "We assume that `app` holds a [Vespa](reference-api.rst#vespa.application.Vespa) connection instance to the desired Vespa application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-tribute",
   "metadata": {},
   "source": [
    "## Feed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-discovery",
   "metadata": {},
   "source": [
    "We can either feed a batch of data for convenience or feed individual data points for increased control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-saturday",
   "metadata": {},
   "source": [
    "### Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-wound",
   "metadata": {},
   "source": [
    "We need to prepare the data as a list of dicts having the `id` key holding a unique id of the data point and the `fields` key holding a dict with the data fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_feed = [\n",
    "    {\n",
    "        \"id\": idx, \n",
    "        \"fields\": sentence\n",
    "    }\n",
    "    for idx, sentence in enumerate(sentence_data)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-dominant",
   "metadata": {},
   "source": [
    "We then feed the batch to the desired schema using the\n",
    "[feed_batch](reference-api.rst#vespa.application.Vespa.feed_batch) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-jamaica",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful documents fed: 100/100.\n",
      "Batch progress: 1/1.\n"
     ]
    }
   ],
   "source": [
    "response = app.feed_batch(schema=\"sentence\", batch=batch_feed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-hudson",
   "metadata": {},
   "source": [
    "### Individual data points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-shell",
   "metadata": {},
   "source": [
    "#### Synchronous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-possible",
   "metadata": {},
   "source": [
    "Syncronously feeding individual data points is similar to batch feeding, except that you have more control when looping through your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = []\n",
    "for idx, sentence in enumerate(sentence_data):\n",
    "    response.append(\n",
    "        app.feed_data_point(schema=\"sentence\", data_id=idx, fields=sentence)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-cattle",
   "metadata": {},
   "source": [
    "#### Asynchronous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-tourist",
   "metadata": {},
   "source": [
    "`app.asyncio()` returns a `VespaAsync` instance that contains async operations such as `feed_data_point`. Using the `async with`  context manager ensures that we open and close the appropriate connections required for async feeding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with app.asyncio() as async_app:\n",
    "    response = await async_app.feed_data_point(\n",
    "        schema=\"sentence\",\n",
    "        data_id=idx,\n",
    "        fields=sentence,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-convenience",
   "metadata": {},
   "source": [
    "We can then use asyncio constructs like `create_task` and `wait` to create different types of asynchronous flows like the one below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asyncio import create_task, wait, ALL_COMPLETED\n",
    "\n",
    "async with app.asyncio() as async_app:\n",
    "    feed = []\n",
    "    for idx, sentence in enumerate(sentence_data):\n",
    "        feed.append(\n",
    "            create_task(\n",
    "                async_app.feed_data_point(\n",
    "                    schema=\"sentence\",\n",
    "                    data_id=idx,\n",
    "                    fields=sentence,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    await wait(feed, return_when=ALL_COMPLETED)\n",
    "    response = [x.result() for x in feed]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-border",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**: The code above runs from a Jupyter Notebook because it already has its async event loop running in the background. You must create your event loop when running this code on an environment without one, just like any asyncio code requires.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-flower",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-ancient",
   "metadata": {},
   "source": [
    "Similarly to the examples about feeding, we can get a batch of data for convenience or get individual data points for increased control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-miniature",
   "metadata": {},
   "source": [
    "### Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-closure",
   "metadata": {},
   "source": [
    "We need to prepare the data as a list of dicts having the `id` key holding a unique id of the data point.\n",
    "We then get the batch from the desired schema using the\n",
    "[get_batch](reference-api.rst#vespa.application.Vespa.get_batch) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [{\"id\": idx} for idx, sentence in enumerate(sentence_data)]\n",
    "response = app.get_batch(schema=\"sentence\", batch=batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-apache",
   "metadata": {},
   "source": [
    "### Individual data points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-patient",
   "metadata": {},
   "source": [
    "We can get individual data points synchronously or asynchronously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-plaza",
   "metadata": {},
   "source": [
    "#### Synchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = app.get_data(schema=\"sentence\", data_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-spending",
   "metadata": {},
   "source": [
    "#### Asynchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with app.asyncio() as async_app:\n",
    "    response = await async_app.get_data(schema=\"sentence\",data_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-legislature",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**: The code above runs from a Jupyter Notebook because it already has its async event loop running in the background. You must create your event loop when running this code on an environment without one, just like any asyncio code requires.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-bailey",
   "metadata": {},
   "source": [
    "## Update data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-marine",
   "metadata": {},
   "source": [
    "Similarly to the examples about feeding, we can update a batch of data for convenience or update individual data points for increased control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-coalition",
   "metadata": {},
   "source": [
    "### Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-session",
   "metadata": {},
   "source": [
    "We need to prepare the data as a list of dicts having the `id` key holding a unique id of the data point, the `fields` key holding a dict with the fields to be updated and an optional `create` key with a boolean value to indicate if a data point should be created in case it does not exist (default to `False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_update = [\n",
    "    {\n",
    "        \"id\": idx,           # data_id\n",
    "        \"fields\": sentence,  # fields to be updated\n",
    "        \"create\": True       # Optional. Create data point if not exist, default to False.\n",
    "        \n",
    "    }\n",
    "    for idx, sentence in enumerate(sentence_data)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-kitchen",
   "metadata": {},
   "source": [
    "We then update the batch on the desired schema using the\n",
    "[update_batch](reference-api.rst#vespa.application.Vespa.update_batch) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = app.update_batch(schema=\"sentence\", batch=batch_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-gossip",
   "metadata": {},
   "source": [
    "### Individual data points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-dubai",
   "metadata": {},
   "source": [
    "We can update individual data points synchronously or asynchronously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-sixth",
   "metadata": {},
   "source": [
    "#### Synchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = app.update_data(schema=\"sentence\", data_id=0, fields=sentence_data[0], create=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-light",
   "metadata": {},
   "source": [
    "#### Asynchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with app.asyncio() as async_app:\n",
    "    response = await async_app.update_data(schema=\"sentence\",data_id=0, fields=sentence_data[0], create=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-montreal",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**: The code above runs from a Jupyter Notebook because it already has its async event loop running in the background. You must create your event loop when running this code on an environment without one, just like any asyncio code requires.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-border",
   "metadata": {},
   "source": [
    "## Delete data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-invalid",
   "metadata": {},
   "source": [
    "Similarly to the examples about feeding, we can delete a batch of data for convenience or delete individual data points for increased control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-wheel",
   "metadata": {},
   "source": [
    "### Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-serum",
   "metadata": {},
   "source": [
    "We need to prepare the data as a list of dicts having the `id` key holding a unique id of the data point.\n",
    "We then delete the batch from the desired schema using the\n",
    "[delete_batch](reference-api.rst#vespa.application.Vespa.delete_batch) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [{\"id\": idx} for idx, sentence in enumerate(sentence_data)]\n",
    "response = app.delete_batch(schema=\"sentence\", batch=batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-mississippi",
   "metadata": {},
   "source": [
    "### Individual data points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-tolerance",
   "metadata": {},
   "source": [
    "We can delete individual data points synchronously or asynchronously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-tucson",
   "metadata": {},
   "source": [
    "#### Synchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = app.delete_data(schema=\"sentence\", data_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-implement",
   "metadata": {},
   "source": [
    "#### Asynchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with app.asyncio() as async_app:\n",
    "    response = await async_app.delete_data(schema=\"sentence\",data_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-conservative",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**: The code above runs from a Jupyter Notebook because it already has its async event loop running in the background. You must create your event loop when running this code on an environment without one, just like any asyncio code requires.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a hidden cell. It will not show on the documentation HTML.\n",
    "\n",
    "vespa_docker.container.stop(timeout=600)\n",
    "vespa_docker.container.remove()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
