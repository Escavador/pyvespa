{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to evaluate Vespa ranking functions from python\n",
    "\n",
    "> Using [pyvespa](https://pyvespa.readthedocs.io/en/latest/index.html) to evaluate [cord19 search application](https://cord19.vespa.ai/) ranking functions currently in production.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vespa-engine/pyvespa/blob/master/docs/sphinx/source/use_cases/cord19/cord19_download_parse_trec_covid.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate query model baselines\n",
    "\n",
    "> Download and explore TREC-COVID. Split data into training and test sets. Evaluate existing query models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The team behind [vespa.ai](https://vespa.ai/) have built and open-sourced a [CORD-19 search engine](https://cord19.vespa.ai/). Thanks to advanced Vespa features such as [Approximate Nearest Neighbors Search](https://blog.vespa.ai/approximate-nearest-neighbor-search-in-vespa-part-1/) and [Tranformers support via ONNX](https://blog.vespa.ai/introducing-nlp-with-transformers-on-vespa/) it comes with the most advanced NLP methodology applied to search that is currently available.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following sections we will:\n",
    "* Download, parse and explore the TREC-COVID Complete topics and relevance judgements.\n",
    "* Split the data into training and test sets.\n",
    "* Evaluate some query models that are already deployed in the [CORD-19 search engine](https://cord19.vespa.ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install pyvespa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pyvespa` provides a python API to Vespa. It allow us to create, modify, deploy and interact with running Vespa instances. The main goal of the library is to allow for faster prototyping and to facilitate Machine Learning experiments for Vespa applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyvespa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and parse TREC-COVID Complete topics and relevance judgements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files used in this section can be found at https://ir.nist.gov/covidSubmit/data.html. We will download both the topics and the relevance judgements data. Do not worry about what they are just yet, we will explore them soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://ir.nist.gov/covidSubmit/data/topics-rnd5.xml\n",
    "!wget https://ir.nist.gov/covidSubmit/data/qrels-covid_d5_j0.5-5.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topics file is in XML format. We can parse it and store on a dictionary called `topics`. We want to extract a `query`, a `question` and a `narrative` for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "topics = {}\n",
    "root = ET.parse(\"topics-rnd5.xml\").getroot()\n",
    "for topic in root.findall(\"topic\"):\n",
    "    topic_number = topic.attrib[\"number\"]\n",
    "    topics[topic_number] = {}\n",
    "    for query in topic.findall(\"query\"):\n",
    "        topics[topic_number][\"query\"] = query.text\n",
    "    for question in topic.findall(\"question\"):\n",
    "        topics[topic_number][\"question\"] = question.text        \n",
    "    for narrative in topic.findall(\"narrative\"):\n",
    "        topics[topic_number][\"narrative\"] = narrative.text        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/Users/tmartins/projects/sw/thigm85.github.io/data/cord19/topics.json\", \"w\") as f:\n",
    "    f.write(json.dumps(topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a total of 50 topics. For example, we can see the first topic below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics[\"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/Users/tmartins/projects/sw/thigm85.github.io/data/cord19/labelled_data.json\", \"w\") as f:\n",
    "    f.write(json.dumps(labelled_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevance judgements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load the relevance judgement data directly into a pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "relevance_data = pd.read_csv(\"qrels-covid_d5_j0.5-5.txt\", sep=\" \", header=None)\n",
    "relevance_data.columns = [\"topic_id\", \"round_id\", \"cord_uid\", \"relevancy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relevance data contain all the relevance judgements made through out the 5 rounds of the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>round_id</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>005b2j4b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>00fmeepz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>010vptx3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0194oljo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>021q9884</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id  round_id  cord_uid  relevancy\n",
       "0         1       4.5  005b2j4b          2\n",
       "1         1       4.0  00fmeepz          1\n",
       "2         1       0.5  010vptx3          2\n",
       "3         1       2.5  0194oljo          1\n",
       "4         1       4.0  021q9884          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to remore two rows that have relevancy equal to -1, which I am assuming is an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>round_id</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55873</th>\n",
       "      <td>38</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9hbib8b3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69173</th>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ucipq8uk</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic_id  round_id  cord_uid  relevancy\n",
       "55873        38       5.0  9hbib8b3         -1\n",
       "69173        50       5.0  ucipq8uk         -1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance_data[relevance_data.relevancy == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_data = relevance_data[relevance_data.relevancy >= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below show that some topics have a higher number of identified relevant document than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_data.to_csv(\"/Users/tmartins/projects/sw/thigm85.github.io/data/cord19/relevance_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(relevance_data, x=\"topic_id\", color = \"relevancy\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "topics = json.loads(\n",
    "    requests.get(\"https://thigm85.github.io/data/cord19/topics.json\").text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv(\"https://thigm85.github.io/data/cord19/relevance_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "relevance_data = read_csv(\"https://thigm85.github.io/data/cord19/relevance_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>round_id</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>005b2j4b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>00fmeepz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>010vptx3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0194oljo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>021q9884</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id  round_id  cord_uid  relevancy\n",
       "0         1       4.5  005b2j4b          2\n",
       "1         1       4.0  00fmeepz          1\n",
       "2         1       0.5  010vptx3          2\n",
       "3         1       2.5  0194oljo          1\n",
       "4         1       4.0  021q9884          1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and split labelled data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include all judgments, including 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_data = [\n",
    "    {\n",
    "        \"query_id\": int(topic_id), \n",
    "        \"query\": topics[topic_id][\"query\"], \n",
    "        \"relevant_docs\": [\n",
    "            {\n",
    "                \"id\": row[\"cord_uid\"], \n",
    "                \"score\": row[\"relevancy\"]\n",
    "            } for idx, row in relevance_data[relevance_data.topic_id == int(topic_id)].iterrows() if row[\"relevancy\"] >= 0\n",
    "        ]\n",
    "    } for topic_id in topics.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"labelled_data_all.json\", \"w\") as f:\n",
    "    f.write(json.dumps(labelled_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the labelled data into pyvespa friendly format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some labelled data. `pyvespa` expects labelled data to follow the format illustrated below. It is a list of dict where each dict represents a query containing `query_id`, `query` and a list of relevant_docs. Each relevant document contain a required `id` key and an optional `score` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_data = [\n",
    "    {\n",
    "        \"query_id\": int(topic_id), \n",
    "        \"query\": topics[topic_id][\"query\"], \n",
    "        \"relevant_docs\": [\n",
    "            {\n",
    "                \"id\": row[\"cord_uid\"], \n",
    "                \"score\": row[\"relevancy\"]\n",
    "            } for idx, row in relevance_data[relevance_data.topic_id == int(topic_id)].iterrows() if row[\"relevancy\"] > 0\n",
    "        ]\n",
    "    } for topic_id in topics.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look how this look like for the first two query topics below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"labelled_data.json\", \"w\") as f:\n",
    "    f.write(json.dumps(labelled_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that each query topic has many relevant documents associated with it. We only kept the relevant documents (scores > 0) because we will later collect non-relevant documents based on how we want to use the data to train models to improve the application relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the labelled data into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Consider adding the split data functionality below to pyvespa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "random.seed(87345634876)\n",
    "\n",
    "# inputs \n",
    "query_prob = 0.2 # Percentage of queries to move to the test set\n",
    "relevant_docs_prob = 0.2 # Percentage of relevant docs to move to the test set\n",
    "\n",
    "\n",
    "\n",
    "# First lets move some query topics to the test set\n",
    "number_queries = len(labelled_data)\n",
    "\n",
    "\n",
    "test_query_idx = [x for x in range(number_queries) if \n",
    "                      x in random.sample(\n",
    "                          population=range(number_queries), \n",
    "                          k=math.floor(number_queries*query_prob)\n",
    "                      )\n",
    "                 ]\n",
    "test_unobserved = [labelled_data[i] for i in range(number_queries) if i in test_query_idx]\n",
    "train_set = [labelled_data[i] for i in range(number_queries) if i not in test_query_idx]\n",
    "\n",
    "test_partially_observed = []\n",
    "for data in train_set:\n",
    "    number_relevant_docs = len(data[\"relevant_docs\"])\n",
    "    test_relevant_docs_idx = [x for x in range(number_relevant_docs) if \n",
    "                                  x in random.sample(\n",
    "                                      population=range(number_relevant_docs),\n",
    "                                      k=math.floor(number_relevant_docs*relevant_docs_prob)\n",
    "                                  )\n",
    "                             ]\n",
    "    test_data = {k:data[k] for k in data.keys() if k != \"relevant_docs\"}\n",
    "    test_data[\"relevant_docs\"] = [\n",
    "        data[\"relevant_docs\"][i] for i in range(number_relevant_docs) \n",
    "        if i in test_relevant_docs_idx\n",
    "    ]\n",
    "    test_partially_observed.append(test_data)\n",
    "    data[\"relevant_docs\"] = [\n",
    "        data[\"relevant_docs\"][i] for i in range(number_relevant_docs) \n",
    "        if i not in test_relevant_docs_idx\n",
    "    ]\n",
    "\n",
    "test_sets = {\n",
    "    \"partially_observed\": test_partially_observed,\n",
    "    \"unobserved\": test_unobserved\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate existing query models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define query models that we want to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.query import Query, RankProfile, OR\n",
    "\n",
    "query_models = {\n",
    "    \"or_bm25\": Query(\n",
    "        match_phase = OR(),\n",
    "        rank_profile = RankProfile(name=\"bm25\")\n",
    "    ),\n",
    "    \"or_bm25t5\": Query(\n",
    "        match_phase = OR(),\n",
    "        rank_profile = RankProfile(name=\"bm25t5\")\n",
    "    ),\n",
    "    \"or_bm25t5-gbdt-1000\": Query(\n",
    "        match_phase = OR(),\n",
    "        rank_profile = RankProfile(name=\"bm25t5-gbdt-1000\")\n",
    "    )\n",
    "}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.evaluation import MatchRatio, Recall, ReciprocalRank, NormalizedDiscountedCumulativeGain\n",
    "\n",
    "eval_metrics = [MatchRatio(), Recall(at=10), ReciprocalRank(at=10), NormalizedDiscountedCumulativeGain(at=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.application import Vespa\n",
    "\n",
    "app = Vespa(url = \"https://api.cord19.vespa.ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = {}\n",
    "for test_set in test_sets:\n",
    "    evaluations[test_set] = {}\n",
    "    for query_model in query_models:\n",
    "        evaluations[test_set][query_model] = app.evaluate(\n",
    "            labelled_data = test_sets[test_set],\n",
    "            eval_metrics = eval_metrics,\n",
    "            query_model = query_models[query_model],\n",
    "            id_field = \"cord_uid\",\n",
    "            hits = 10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metric_values = []\n",
    "for test_set in test_sets:\n",
    "    for query_model in query_models:\n",
    "        for metric in eval_metrics:\n",
    "            metric_values.append(\n",
    "                pd.DataFrame(\n",
    "                    data={\n",
    "                        \"test_set\": test_set, \n",
    "                        \"query_model\": query_model, \n",
    "                        \"metric\": metric.name, \n",
    "                        \"value\": evaluations[test_set][query_model][metric.name + \"_value\"].to_list()\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "metric_values = pd.concat(metric_values, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_values.metric.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.box(metric_values[metric_values.metric == \"ndcg_10\"], x=\"query_model\", y=\"value\", title=\"Ndgc @ 10\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_values.groupby(['query_model', 'metric']).median()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
