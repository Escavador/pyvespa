import re
import json
import random
import os
from typing import Optional, List, Dict
import os.path

from vespa.package import (
    ApplicationPackage,
    Schema,
    Document,
    Field,
    FieldSet,
    RankProfile as Ranking,
    QueryProfile,
    QueryField,
)

REPLACE_SYMBOLS = ["(", ")", " -", " +"]
QUOTES = [
    "\u0022",  # quotation mark (")
    "\u0027",  # apostrophe (')
    "\u00ab",  # left-pointing double-angle quotation mark
    "\u00bb",  # right-pointing double-angle quotation mark
    "\u2018",  # left single quotation mark
    "\u2019",  # right single quotation mark
    "\u201a",  # single low-9 quotation mark
    "\u201b",  # single high-reversed-9 quotation mark
    "\u201c",  # left double quotation mark
    "\u201d",  # right double quotation mark
    "\u201e",  # double low-9 quotation mark
    "\u201f",  # double high-reversed-9 quotation mark
    "\u2039",  # single left-pointing angle quotation mark
    "\u203a",  # single right-pointing angle quotation mark
    "\u300c",  # left corner bracket
    "\u300d",  # right corner bracket
    "\u300e",  # left white corner bracket
    "\u300f",  # right white corner bracket
    "\u301d",  # reversed double prime quotation mark
    "\u301e",  # double prime quotation mark
    "\u301f",  # low double prime quotation mark
    "\ufe41",  # presentation form for vertical left corner bracket
    "\ufe42",  # presentation form for vertical right corner bracket
    "\ufe43",  # presentation form for vertical left corner white bracket
    "\ufe44",  # presentation form for vertical right corner white bracket
    "\uff02",  # fullwidth quotation mark
    "\uff07",  # fullwidth apostrophe
    "\uff62",  # halfwidth left corner bracket
    "\uff63",  # halfwidth right corner bracket
]
REPLACE_SYMBOLS.extend(QUOTES)


class Dataset:
    def __init__(self):
        """
        Convenient functions to remove special symbols from queries.
        """
        pass

    @staticmethod
    def replace_symbols(x):
        for symbol in REPLACE_SYMBOLS:
            x = x.replace(symbol, "")
        return x

    @staticmethod
    def parse_query(query):
        return re.sub(" +", " ", Dataset.replace_symbols(query)).strip()


class BeirData:
    def __init__(self, data_dir: str):
        """
        Download, sample and standardized data format to be used in the ranking framework.

        :param data_dir: Root folder to store datasets
        """
        self.data_dir = data_dir

    def save_data(self, data: Dict, file_name: str = "sample.json"):
        """
        Convenient function to save sample data

        :param data: data generated by :func:`sample_data`.
        :param file_name: Name of the file to store the sample data
        """
        file_path = os.path.join(self.data_dir, file_name)
        with open(file_path, "w") as f:
            json.dump(data, f)

    def load_data(self, file_name: str = "sample.json"):
        """
        Load data sample

        :param file_name: Name of the data file.
        :return: Sample data
        """
        file_path = os.path.join(self.data_dir, file_name)
        with open(file_path, "r") as f:
            data = json.load(f)
        return data

    @staticmethod
    def sample_positive_data(qrels, queries, number_samples):
        """
        Sample qrels, queries and positive document ids.

        :param qrels: Dict containing query id as key and a dict with doc_id:score as value.
        :param queries: Dict containing query id as key and query string as value.
        :param number_samples: The number of positive (query_id, relevant_doc)-pairs to sample.

        :return: Tuple with the following elements: qrels_sample, queries_sample and positive_id_sample
        """

        qrels_sample = {
            k: qrels[k]
            for k in random.sample(k=number_samples, population=sorted(qrels))
        }
        queries_sample = {k: queries[k] for k in qrels_sample.keys()}
        positive_id_sample = [
            doc_id[0]
            for doc_id in [list(docs.keys()) for docs in qrels_sample.values()]
        ]
        return qrels_sample, queries_sample, positive_id_sample

    def sample_data(
        self,
        data: Dict,
        number_positive_samples: int,
        number_negative_samples: int,
        split_types: Optional[List] = None,
        seed: Optional[int] = None,
    ):
        """
        Routine to sample smaller datasets for prototyping.

        :param data: data containing corpus and qrels and queries split.
        :param number_positive_samples: The number of positive (query_id, relevant_doc)-pairs to select.
            If number_positive_samples=100 it means we will sample 100 pairs for each split type.
            The relevant documents will be included in the document corpus.
        :param number_negative_samples: The number of documents to be randomly chosen from the document corpus, in
            addition to the relevant documents sampled.
        :param split_types: A list containing a combination of 'train', 'dev' and 'test' set.
            Default to ['train', 'dev']
        :param seed: Seed to initialize the random number generator.

        :return: Dict containing the following keys: 'corpus', 'train_qrels', 'train_queries', 'dev_qrels', 'dev_queries'.
        """
        if seed:
            random.seed(seed)

        if not split_types:
            split_types = ["train", "dev"]

        assert len(split_types) > 0, "Specify at least one split_type."

        positive_ids = []
        split = {}
        corpus = None
        for split_type in split_types:
            corpus = data["corpus"]
            queries = data["split"][split_type]["queries"]
            qrels = data["split"][split_type]["qrels"]
            (
                qrels_sample,
                queries_sample,
                positive_id_sample,
            ) = self.sample_positive_data(
                qrels=qrels,
                queries=queries,
                number_samples=number_positive_samples,
            )
            positive_ids = positive_ids + positive_id_sample
            split[split_type] = {"qrels": qrels_sample, "queries": queries_sample}

        negative_ids = random.sample(
            k=number_negative_samples, population=sorted(corpus)
        )
        doc_id_samples = list(set(positive_ids + negative_ids))
        corpus_sample = {k: corpus[k] for k in doc_id_samples}

        return {"corpus": corpus_sample, "split": split}


class SparseBeirApplicationPackage(ApplicationPackage):
    def __init__(self, name: str = "SparseBeir"):
        """
        Create an application package suited to perform sparse ranking on beir data.

        :param name: Name of the application package
        """
        document = Document(
            fields=[
                Field(name="id", type="string", indexing=["attribute", "summary"]),
                Field(
                    name="title",
                    type="string",
                    indexing=["index"],
                    index="enable-bm25",
                ),
                Field(
                    name="body",
                    type="string",
                    indexing=["index"],
                    index="enable-bm25",
                ),
            ]
        )
        schema = Schema(
            name=name,
            document=document,
            fieldsets=[FieldSet(name="default", fields=["title", "body"])],
            rank_profiles=[
                Ranking(
                    name="bm25",
                    first_phase="bm25(body)",
                    summary_features=["bm25(body)"],
                ),
                Ranking(name="native_rank", first_phase="nativeRank(body)"),
                Ranking(name="random", first_phase="random"),
            ],
        )
        super().__init__(
            name=name,
            schema=[schema],
            query_profile=QueryProfile(
                fields=[QueryField(name="maxHits", value=10000)]
            ),
        )

    def add_first_phase_linear_model(self, name, weights):
        """
        Add a linear model as a first phase ranking

        :param name: Name of the ranking profile.
        :param weights: Dict containing feature name as key and weight value as value.
        """
        self.schema.add_rank_profile(
            Ranking(
                name=name,
                first_phase=" + ".join(
                    ["{} * {}".format(k, v) for k, v in weights.items()]
                ),
            )
        )
